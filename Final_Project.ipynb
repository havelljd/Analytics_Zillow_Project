{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "x-gLwkizljoR",
        "K0aXY06fKp6L",
        "Jv0OM7hrLum_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall pandas\n",
        "# !pip install pandas==1.1.5\n",
        "!pip install pyLDAvis\n",
        "!pip install pyLDAvis.gensim\n",
        "# !pip install bokeh\n",
        "# !pip install gensim\n",
        "# !pip install spacy\n",
        "!pip install logging\n",
        "# !pip install wordcloud\n",
        "# !pip install nltk\n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "# !pip install -U seaborn\n",
        "# !pip install translators --upgrade\n",
        "# !pip install --upgrade pip\n",
        "!pip install apify_client\n",
        "!pip install gower"
      ],
      "metadata": {
        "id": "TCs8yqaecdP_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d768804-1fcd-41e4-a8b2-f52442a197b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Collecting numpy>=1.20.0\n",
            "  Downloading numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading funcy-1.16-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Collecting pandas>=1.2.0\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 31.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.0.0)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136897 sha256=e0ed558bb6c0003de1eb6d07ddc4e3bd1f593c443d31a112ca5263b328610d85\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/21/f6/17bcf2667e8a68532ba2fbf6d5c72fdf4c7f7d9abfa4852d2f\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: numpy, pandas, funcy, pyLDAvis\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed funcy-1.16 numpy-1.21.4 pandas-1.3.5 pyLDAvis-3.3.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyLDAvis.gensim (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pyLDAvis.gensim\u001b[0m\n",
            "Collecting logging\n",
            "  Downloading logging-0.4.9.6.tar.gz (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 2.9 MB/s \n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/93/4b/979db9e44be09f71e85c9c8cfc42f258adfb7d93ce01deed2788b2948919/logging-0.4.9.6.tar.gz#sha256=26f6b50773f085042d301085bd1bf5d9f3735704db9f37c1ce6d8b85c38f2417 (from https://pypi.org/simple/logging/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement logging (from versions: 0.4.9.6)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for logging\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-59.6.0-py3-none-any.whl (952 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.0)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed pip-21.3.1 setuptools-59.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "     |████████████████████████████████| 6.0 MB 4.9 MB/s            \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (59.6.0)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "     |████████████████████████████████| 10.1 MB 44.9 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.4)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "     |████████████████████████████████| 628 kB 31.1 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "     |████████████████████████████████| 451 kB 49.5 MB/s            \n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "     |████████████████████████████████| 42 kB 1.2 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "     |████████████████████████████████| 181 kB 57.5 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 spacy-3.2.1 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting en-core-web-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
            "     |████████████████████████████████| 13.9 MB 5.2 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (59.6.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-3.2.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Collecting apify_client\n",
            "  Downloading apify_client-0.5.0-py3-none-any.whl (55 kB)\n",
            "     |████████████████████████████████| 55 kB 2.3 MB/s             \n",
            "\u001b[?25hCollecting requests~=2.26.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "     |████████████████████████████████| 62 kB 771 kB/s             \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests~=2.26.0->apify_client) (2.0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.26.0->apify_client) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.26.0->apify_client) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.26.0->apify_client) (1.24.3)\n",
            "Installing collected packages: requests, apify-client\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apify-client-0.5.0 requests-2.26.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting gower\n",
            "  Downloading gower-0.0.5.tar.gz (4.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gower) (1.21.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gower) (1.4.1)\n",
            "Building wheels for collected packages: gower\n",
            "  Building wheel for gower (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gower: filename=gower-0.0.5-py3-none-any.whl size=4231 sha256=d6ccea3abc09d788fe9c592b94fc8b6bbc78f51bdca5916d4705fa15d878ec1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/f9/9a/67122a959a424e9cbb4557a8366c871a30e31cd75f0d003db4\n",
            "Successfully built gower\n",
            "Installing collected packages: gower\n",
            "Successfully installed gower-0.0.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API Call and Setting DF"
      ],
      "metadata": {
        "id": "WJloNHc3gfhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataframe():\n",
        "\n",
        "  from apify_client import ApifyClient\n",
        "  import pandas as pd\n",
        "\n",
        "  # Initialize the ApifyClient with your API token\n",
        "  client = ApifyClient(\"Removed For GitHub Public\")\n",
        "\n",
        "  # Prepare the actor input\n",
        "  run_input = {\n",
        "      \"search\": \"Utah\",\n",
        "      \"maxLevel\": 5,\n",
        "      \"maxItems\": 1000,\n",
        "      \"proxyConfiguration\": { \"useApifyProxy\": True },\n",
        "      \"maxRetries\": 20,\n",
        "      \"extendOutputFunction\": \"\"\"async ({ data, item, customData, Apify }) => {\n",
        "      return item;\n",
        "  }\"\"\",\n",
        "      \"extendScraperFunction\": \"\"\"async ({ label, page, request, customData, Apify }) => {\n",
        "      if (label === 'SETUP') {\n",
        "          // before crawler.run()\n",
        "      } else if (label === 'GOTO') {\n",
        "          // inside handleGotoFunction\n",
        "      } else if (label === 'HANDLE') {\n",
        "          // inside handlePageFunction\n",
        "      } else if (label === 'FINISH') {\n",
        "          // after crawler.run()\n",
        "      }\n",
        "  }\"\"\",\n",
        "      \"customData\": {},\n",
        "      \"handlePageTimeoutSecs\": 3600,\n",
        "      \"type\": \"sale\"\n",
        "  }\n",
        "\n",
        "  # Run the actor and wait for it to finish\n",
        "  run = client.actor(\"petr_cermak/zillow-api-scraper\").call(run_input=run_input)\n",
        "\n",
        "\n",
        "  for count, item in enumerate(client.dataset(run[\"defaultDatasetId\"]).iterate_items()):\n",
        "    df_data = pd.Series(item)\n",
        "\n",
        "    city = {'city': df_data[0]['city']}\n",
        "    zipcode = { 'zipcode': df_data[0]['zipcode']}\n",
        "\n",
        "    df_data.drop(labels = 'address', inplace=True)\n",
        "    df_data.drop(labels = 'homeStatus', inplace=True)\n",
        "    df_data.drop(labels = 'url', inplace=True)\n",
        "    df_data.drop(labels = 'currency', inplace=True)\n",
        "\n",
        "    df_data = df_data.append(pd.Series(city))\n",
        "    df_data = df_data.append(pd.Series(zipcode))\n",
        "\n",
        "    photo = df_data['photos'][0]\n",
        "\n",
        "    df_data['photos'] = photo\n",
        "    df_data['id'] = count\n",
        "\n",
        "    if(count == 0):\n",
        "      df = df_data\n",
        "    else:\n",
        "      df = pd.concat([df_data, df], axis=1)\n",
        "  df = df.transpose()\n",
        "  df.set_index('id', inplace=True)\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "BUpk5Oc5gjLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import all necessary packages\n",
        "import sys\n",
        "import re\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "import seaborn as sns\n",
        "import matplotlib.colors as mcolors\n",
        "import math\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Gensim\n",
        "import gensim, spacy, logging, warnings\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import lemmatize, simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "import nltk"
      ],
      "metadata": {
        "id": "p_UMLDFCelm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "808f990b-a07b-4274-f53a-5a95efc26883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "\n",
        "# Functions"
      ],
      "metadata": {
        "id": "UsYoiicCXI70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(df):\n",
        "\n",
        "  # Remove rows that contain missing data\n",
        "  df = df[df['photos'].str.contains('google') == False]\n",
        "  df = df[df['bathrooms'].notna()]\n",
        "  df = df[df['bedrooms'].notna()]\n",
        "  df = df[df['livingArea'].notna()]\n",
        "  df = df[df['description'].notna()]\n",
        "  df = df[df['yearBuilt'].notna()]\n",
        "  df = df[df['yearBuilt'] != 0.0]\n",
        "  df = df[df['bedrooms'] != 0.0]\n",
        "  df = df[df['bathrooms'] != 0.0]\n",
        "  df.fillna(0, inplace=True)\n",
        "  df = df[df['price'] != 0.0]\n",
        "\n",
        "  # Create sample of data\n",
        "  df = df.sample(460, random_state = 12345)\n",
        "\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "QwPDre4uSLb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_to_words(sentences):\n",
        "  for sent in sentences:\n",
        "    sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
        "    sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
        "    sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
        "    sent = re.sub(\"\\\"\", \"\", sent) # remove double quotes\n",
        "    sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "    yield(sent)   "
      ],
      "metadata": {
        "id": "0W2xJCjXddDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_words(texts, stop_words=[], allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "  \"\"\"Remove Stopwords, Form Bigrams, Trigrams and perform Lemmatization\"\"\"\n",
        "  texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "  texts = [bigram_mod[doc] for doc in texts]\n",
        "  texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "      \n",
        "  texts_out = []\n",
        "  nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])    # Load spacy, but we don't need the parser or NER (named entity extraction) modules\n",
        "      \n",
        "  for sent in texts:\n",
        "    doc = nlp(\" \".join(sent)) \n",
        "    texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "        \n",
        "  # remove stopwords once more after lemmatization\n",
        "  texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
        "  \n",
        "  return texts_out"
      ],
      "metadata": {
        "id": "Pc-qpbixddM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scored_text_df_graphs(df, text_label, stop_list = [''], num_topics = 3, min_count = 5, threshold = 50, random_state = 12345, chunksize = 100, passes = 5, per_word_topics = True):\n",
        "\n",
        "  def sent_to_words(sentences):\n",
        "    for sent in sentences:\n",
        "      sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
        "      sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
        "      sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
        "      sent = re.sub(\"\\\"\", \"\", sent) # remove double quotes\n",
        "      sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "      yield(sent)  \n",
        "\n",
        "  def process_words(texts, stop_words=[''], allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and perform Lemmatization\"\"\"\n",
        "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "    texts = [bigram_mod[doc] for doc in texts]\n",
        "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "        \n",
        "    texts_out = []\n",
        "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])    # Load spacy, but we don't need the parser or NER (named entity extraction) modules\n",
        "        \n",
        "    for sent in texts:\n",
        "      doc = nlp(\" \".join(sent)) \n",
        "      texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "          \n",
        "    # remove stopwords once more after lemmatization\n",
        "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
        "    return texts_out\n",
        "\n",
        "  #Import all necessary packages\n",
        "  import sys\n",
        "  import re\n",
        "  import numpy as np\n",
        "  from pprint import pprint\n",
        "  import seaborn as sns\n",
        "  import matplotlib.colors as mcolors\n",
        "  import math\n",
        "\n",
        "  # Gensim\n",
        "  import gensim, spacy, logging, warnings\n",
        "  import gensim.corpora as corpora\n",
        "  from gensim.utils import lemmatize, simple_preprocess\n",
        "  from gensim.models import CoherenceModel\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  # NLTK Stop words\n",
        "  from nltk.corpus import stopwords\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  stop_words = stopwords.words('english')\n",
        "  stop_words.extend(stop_list) # After reviewering the LDA, return to add words that you want to eliminate\n",
        "\n",
        "  # Convert each tweet to a list of cleaned words and add to a master list\n",
        "  data = df[text_label].values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "\n",
        "  # Build the bigram and trigram models\n",
        "  bigram = gensim.models.Phrases(data_words, min_count=min_count, threshold=threshold) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_words], threshold=threshold)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "  # Processed and ready text data\n",
        "  data_ready = process_words(data_words, stop_words = stop_words)\n",
        "\n",
        "  # Creation of corpus of all words in data sample\n",
        "  id2word = corpora.Dictionary(data_ready)\n",
        "  corpus = [id2word.doc2bow(text) for text in data_ready]\n",
        "\n",
        "  # Model that is created\n",
        "  lda_model = gensim.models.ldamodel.LdaModel(  corpus=corpus, \n",
        "                                                id2word=id2word, \n",
        "                                                num_topics=num_topics, \n",
        "                                                random_state=random_state,\n",
        "                                                chunksize=chunksize, \n",
        "                                                passes=passes,\n",
        "                                                per_word_topics=per_word_topics  )\n",
        "\n",
        "  num_topics = len(lda_model.get_topics()) # store the number of topics from the last model\n",
        "  for col in range(num_topics): # generate a new column for each topic\n",
        "    df[f'topic_{col + 1}'] = 0.0\n",
        "    \n",
        "  # Store the topic score and dominant topic\n",
        "  for i, words in enumerate(data_ready):\n",
        "    doc = lda_model[id2word.doc2bow(words)] # generate a corpus for this document set of words\n",
        "    \n",
        "    for j, score in enumerate(doc[0]): # for each document in the corpus\n",
        "      # Get the topic score and store it in the appropriate column\n",
        "      df.iat[i, (len(df.columns) - ((num_topics) - score[0]))] = score[1]\n",
        "\n",
        "  df_scored = df.copy()\n",
        "\n",
        "  # Plots and Figures to Analyze Accuracy and Distribution\n",
        "\n",
        "  #Barchart of Text Distances\n",
        "  doc_lens = [len(d) for d in data_ready]\n",
        "\n",
        "  plt.figure(figsize=(18,7))\n",
        "  sns.displot(doc_lens, bins=27)\n",
        "  plt.gca().set(ylabel=f'Number of {text_label}', xlabel=f'{text_label} Word Count')\n",
        "  plt.title(f'Distribution of {text_label} Word Counts')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  # Use the following chart to identify stopwords for each category\n",
        "\n",
        "  # Bar chart of word counts for each topic\n",
        "  from collections import Counter\n",
        "  topics = lda_model.show_topics(formatted=False)\n",
        "  data_flat = [w for w_list in data_ready for w in w_list]\n",
        "  counter = Counter(data_flat)\n",
        "\n",
        "  out = []\n",
        "  for i, topic in topics:\n",
        "      for word, weight in topic:\n",
        "          out.append([word, i , weight, counter[word]])\n",
        "\n",
        "  df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n",
        "\n",
        "  # Plot Word Count and Weights of Topic Keywords\n",
        "  fig, axes = plt.subplots(3, math.ceil(len(topics)/3), figsize=(16,10), sharey=True, dpi=160)\n",
        "\n",
        "  cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
        "  for i, ax in enumerate(axes.flatten()):\n",
        "      ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
        "      ax_twin = ax.twinx()\n",
        "      ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
        "      ax.set_ylabel('Word Count', color=cols[i])\n",
        "      # ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n",
        "      ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n",
        "      ax.tick_params(axis='y', left=False)\n",
        "      ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
        "      ax.legend(loc='upper center'); ax_twin.legend(loc='upper right')\n",
        "\n",
        "  fig.tight_layout(w_pad=2)    \n",
        "  fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)    \n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  # Visualize distribution of each data point across text categories\n",
        "\n",
        "  # Get topic weights and dominant topics\n",
        "  from sklearn.manifold import TSNE\n",
        "  from bokeh.plotting import figure, output_file, show\n",
        "  from bokeh.models import Label\n",
        "  from bokeh.io import output_notebook\n",
        "\n",
        "  # Get topic weights\n",
        "  topic_weights = []\n",
        "  for i, row_list in enumerate(lda_model[corpus]):\n",
        "      topic_weights.append([w for i, w in row_list[0]])\n",
        "\n",
        "  # Array of topic weights    \n",
        "  arr = pd.DataFrame(topic_weights).fillna(0).values\n",
        "\n",
        "  # Keep the well separated points (optional)\n",
        "  arr = arr[np.amax(arr, axis=1) > 0.35]\n",
        "\n",
        "  # Dominant topic number in each doc\n",
        "  topic_num = np.argmax(arr, axis=1)\n",
        "\n",
        "  # tSNE Dimension Reduction\n",
        "  tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
        "  tsne_lda = tsne_model.fit_transform(arr)\n",
        "\n",
        "  # Plot the Topic Clusters using Bokeh\n",
        "  output_notebook()\n",
        "  n_topics = 4\n",
        "  mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
        "  plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics), \n",
        "                plot_width=900, plot_height=700)\n",
        "  plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
        "  show(plot)\n",
        "  \n",
        "  return df_scored\n",
        "  "
      ],
      "metadata": {
        "id": "2lNUfP7uSPR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scored_text_df(df, text_label, stop_list = [''], num_topics = 3, min_count = 5, threshold = 50, random_state = 12345, chunksize = 100, passes = 5, per_word_topics = True):\n",
        "\n",
        "  def sent_to_words(sentences):\n",
        "    for sent in sentences:\n",
        "      sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
        "      sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
        "      sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
        "      sent = re.sub(\"\\\"\", \"\", sent) # remove double quotes\n",
        "      sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
        "      yield(sent)  \n",
        "\n",
        "  def process_words(texts, stop_words=[''], allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and perform Lemmatization\"\"\"\n",
        "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "    texts = [bigram_mod[doc] for doc in texts]\n",
        "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "        \n",
        "    texts_out = []\n",
        "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])    # Load spacy, but we don't need the parser or NER (named entity extraction) modules\n",
        "        \n",
        "    for sent in texts:\n",
        "      doc = nlp(\" \".join(sent)) \n",
        "      texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "          \n",
        "    # remove stopwords once more after lemmatization\n",
        "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
        "    return texts_out\n",
        "\n",
        "  #Import all necessary packages\n",
        "  import sys\n",
        "  import re\n",
        "  import numpy as np\n",
        "  from pprint import pprint\n",
        "  import seaborn as sns\n",
        "  import matplotlib.colors as mcolors\n",
        "  import math\n",
        "\n",
        "  # Gensim\n",
        "  import gensim, spacy, logging, warnings\n",
        "  import gensim.corpora as corpora\n",
        "  from gensim.utils import lemmatize, simple_preprocess\n",
        "  from gensim.models import CoherenceModel\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  # NLTK Stop words\n",
        "  from nltk.corpus import stopwords\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  stop_words = stopwords.words('english')\n",
        "  stop_words.extend(stop_list) # After reviewering the LDA, return to add words that you want to eliminate\n",
        "\n",
        "  # Convert each tweet to a list of cleaned words and add to a master list\n",
        "  data = df[text_label].values.tolist()\n",
        "  data_words = list(sent_to_words(data))\n",
        "\n",
        "  # Build the bigram and trigram models\n",
        "  bigram = gensim.models.Phrases(data_words, min_count=min_count, threshold=threshold) # higher threshold fewer phrases.\n",
        "  trigram = gensim.models.Phrases(bigram[data_words], threshold=threshold)  \n",
        "  bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "  trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "  # Processed and ready text data\n",
        "  data_ready = process_words(data_words, stop_words = stop_words)\n",
        "\n",
        "  # Creation of corpus of all words in data sample\n",
        "  id2word = corpora.Dictionary(data_ready)\n",
        "  corpus = [id2word.doc2bow(text) for text in data_ready]\n",
        "\n",
        "  # Model that is created\n",
        "  lda_model = gensim.models.ldamodel.LdaModel(  corpus=corpus, \n",
        "                                                id2word=id2word, \n",
        "                                                num_topics=num_topics, \n",
        "                                                random_state=random_state,\n",
        "                                                chunksize=chunksize, \n",
        "                                                passes=passes,\n",
        "                                                per_word_topics=per_word_topics  )\n",
        "\n",
        "  num_topics = len(lda_model.get_topics()) # store the number of topics from the last model\n",
        "  for col in range(num_topics): # generate a new column for each topic\n",
        "    df[f'topic_{col + 1}'] = 0.0\n",
        "    \n",
        "  # Store the topic score and dominant topic\n",
        "  for i, words in enumerate(data_ready):\n",
        "    doc = lda_model[id2word.doc2bow(words)] # generate a corpus for this document set of words\n",
        "    \n",
        "    for j, score in enumerate(doc[0]): # for each document in the corpus\n",
        "      # Get the topic score and store it in the appropriate column\n",
        "      df.iat[i, (len(df.columns) - ((num_topics) - score[0]))] = score[1]\n",
        "\n",
        "  df_scored = df.copy()\n",
        "  \n",
        "  return df_scored.drop(columns = 'description')\n",
        "  "
      ],
      "metadata": {
        "id": "86gXCSrGXxPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bin_groups(df, percent=.04):\n",
        "\n",
        "# no need to use this function, our dataset is clean already\n",
        "\n",
        "    import pandas as pd\n",
        "\n",
        "    for col in df:\n",
        "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
        "            for group, count in df[col].value_counts().iteritems():\n",
        "                if count / len(df) < percent:\n",
        "                    df.loc[df[col] == group, col] = 'Other'\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "KDcJkHMqXzZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dummy_code_df(df):\n",
        "\n",
        "  # Import necessary packages\n",
        "  import pandas as pd\n",
        "\n",
        "  #Dummy code all categorical values\n",
        "  for col in df:\n",
        "    if not pd.api.types.is_numeric_dtype(df[col]):\n",
        "      df = pd.get_dummies(df, columns = [col], drop_first = True)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "GMcR7DDDX12e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_crossvalidate_mlr(df, k, label, repeat = True):\n",
        "\n",
        "  # Import necessary packages\n",
        "  from sklearn.linear_model import LinearRegression\n",
        "  from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score\n",
        "  import pandas as pd\n",
        "  from numpy import mean, std\n",
        "\n",
        "  # Select label and features\n",
        "  X = df.drop(columns = ['livingArea'])\n",
        "  y = df['livingArea']\n",
        "\n",
        "  if repeat:\n",
        "    cv = RepeatedKFold(n_splits = k, n_repeats = 5, random_state = 12345)\n",
        "  else:\n",
        "    cv = KFold(n_splits = k, random_state = 12345, shuffle = True)\n",
        "\n",
        "  # Evaluate Model\n",
        "  scores = cross_val_score(LinearRegression(), X, y, scoring = 'r2', cv = cv, n_jobs = -1)\n",
        "\n",
        "  # Report Performance\n",
        "  print(f'R-squared scores: \\n{scores}\\n')\n",
        "  print(f'Average R-squared:\\t{mean(scores)}')\n",
        "\n",
        "  model = LinearRegression().fit(X, y)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "GBhPF_-bX4NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vif(df):\n",
        "  import pandas as pd\n",
        "  from sklearn.linear_model import LinearRegression\n",
        "\n",
        "  # initialize dictionaries\n",
        "  vif_dict, tolerance_dict = {}, {}\n",
        "\n",
        "  # form input data for each exogenous variable\n",
        "  for col in df:\n",
        "    y = df[col]\n",
        "    X = df.drop(columns=[col])\n",
        "\n",
        "    # extract r-squared from the fit\n",
        "    r_squared = LinearRegression().fit(X, y).score(X, y)\n",
        "\n",
        "    # calculate VIF\n",
        "    vif = 1/(1 - r_squared)\n",
        "\n",
        "    vif_dict[col] = vif\n",
        "\n",
        "    # calculate tolerance\n",
        "    tolerance = 1 - r_squared\n",
        "    tolerance_dict[col] = tolerance\n",
        "\n",
        "\n",
        "  return pd.DataFrame({'VIF': vif_dict, 'Tolerance': tolerance_dict})\n"
      ],
      "metadata": {
        "id": "xD6iL28FX6Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_crossvalidate_reg(df, label, k=10, r=5, repeat=True):\n",
        "  import sklearn.linear_model as lm, pandas as pd, sklearn.ensemble as se\n",
        "  from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score\n",
        "  from numpy import mean, std\n",
        "  from sklearn import svm\n",
        "  from sklearn import gaussian_process\n",
        "  from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
        "  from xgboost import XGBRegressor\n",
        "\n",
        "  X = df.drop(columns=[label])\n",
        "  y = df[label]\n",
        "\n",
        "  if repeat:\n",
        "    cv = RepeatedKFold(n_splits=k, n_repeats=r, random_state=12345)\n",
        "  else:\n",
        "    cv = KFold(n_splits=k, random_state=12345, shuffle=True)\n",
        "\n",
        "  fit = {}    # Use this to store each of the fit metrics\n",
        "  models = {} # Use this to store each of the models\n",
        "\n",
        "  # Create the model objects\n",
        "  model_ols = lm.LinearRegression()\n",
        "  model_rr = lm.Ridge(alpha=0.5) # adjust this alpha parameter for better results (between 0 and 1)\n",
        "  model_lr = lm.Lasso(alpha=0.1) # adjust this alpha parameter for better results (between 0 and 1)\n",
        "  model_llr = lm.LassoLars(alpha=0.1) # adjust this alpha parameter for better results (between 0 and 1)\n",
        "  model_br = lm.BayesianRidge()\n",
        "  model_pr = lm.TweedieRegressor(power=1, link=\"log\") # Power=1 means this is a Poisson\n",
        "  model_gr = lm.TweedieRegressor(power=2, link=\"log\") # Power=2 means this is a Gamma\n",
        "  model_igr = lm.TweedieRegressor(power=3) # Power=3 means this is an inverse Gamma\n",
        "  model_svm = svm.SVR()\n",
        "  model_lsvm = svm.LinearSVR()\n",
        "  model_nusvm = svm.NuSVR()\n",
        "  model_gpr = gaussian_process.GaussianProcessRegressor(DotProduct() + WhiteKernel())\n",
        "  model_df = se.RandomForestRegressor(random_state=12345)\n",
        "  model_etr = se.ExtraTreesRegressor(random_state=12345)\n",
        "  model_abr = se.AdaBoostRegressor(n_estimators=100, random_state=12345)\n",
        "  model_gbr = se.GradientBoostingRegressor(random_state=12345)\n",
        "  model_hgbr = se.HistGradientBoostingRegressor(random_state=12345)\n",
        "  model_vr = se.VotingRegressor(estimators=[('DF', model_df), ('ETR', model_etr), ('ABR', model_abr), ('GBR', model_gbr)])\n",
        "  estimators = [('ridge', lm.RidgeCV()), ('lasso', lm.LassoCV(random_state=42)), ('svr', svm.SVR(C=1, gamma=1e-6))]\n",
        "  model_sr = se.StackingRegressor(estimators=estimators, final_estimator=se.GradientBoostingRegressor(random_state=12345))\n",
        "  model_xgb = XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
        "\n",
        "  # Fit a crss-validated R squared score and add it to the dict\n",
        "  fit['OLS'] = mean(cross_val_score(model_ols, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['Ridge'] = mean(cross_val_score(model_rr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['Lasso'] = mean(cross_val_score(model_lr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['LARS'] = mean(cross_val_score(model_llr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['Bayesian'] = mean(cross_val_score(model_br, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['Poisson'] = mean(cross_val_score(model_pr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['Gamma'] = mean(cross_val_score(model_gr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['Inverse'] = mean(cross_val_score(model_igr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['SupportVM'] = mean(cross_val_score(model_svm, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['Linear SVM'] = mean(cross_val_score(model_lsvm, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['NuSupportVM'] = mean(cross_val_score(model_nusvm, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['GaussianP'] = mean(cross_val_score(model_gpr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['Dec Forest'] = mean(cross_val_score(model_df, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['Extra Trees'] = mean(cross_val_score(model_etr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['AdaBoost DT'] = mean(cross_val_score(model_abr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['Grad. Boost'] = mean(cross_val_score(model_gbr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['HG Boost'] = mean(cross_val_score(model_hgbr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['Voting'] = mean(cross_val_score(model_vr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['Stacking'] = mean(cross_val_score(model_sr, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "  fit['XGBoost'] = mean(cross_val_score(model_xgb, X, y, scoring='r2', cv=cv, n_jobs=-1))\n",
        "\n",
        "  # Add the model to another dict; make sure the keys have the same names as the list above\n",
        "  models['OLS'] = model_ols\n",
        "  models['Ridge'] = model_rr\n",
        "  models['Lasso'] = model_lr\n",
        "  models['LARS'] = model_llr\n",
        "  models['Bayesian'] = model_br\n",
        "  models['Poisson'] = model_pr\n",
        "  models['Gamma'] = model_gr\n",
        "  models['Inverse'] = model_igr\n",
        "  models['SupportVM'] = model_svm\n",
        "  models['Linear SVM'] = model_lsvm\n",
        "  models['NuSupportVM'] = model_nusvm\n",
        "  models['GaussianP'] = model_gpr\n",
        "  models['Dec Forest'] = model_df\n",
        "  models['Extra Trees'] = model_etr\n",
        "  models['AdaBoost DT'] = model_abr\n",
        "  models['Grad. Boost'] = model_gbr\n",
        "  models['HG Boost'] = model_hgbr\n",
        "  models['Voting'] = model_vr\n",
        "  models['Stacking'] = model_sr\n",
        "  models['XGBoost'] = model_xgb\n",
        "\n",
        "  # Add the fit dictionary to a new DataFrame, sort, extract the top row, use it to retrieve the model object from the models dictionary\n",
        "  df_fit = pd.DataFrame({'R-squared':fit})\n",
        "  df_fit.sort_values(by=['R-squared'], ascending=False, inplace=True)\n",
        "  best_model = df_fit.index[0]\n",
        "  print(df_fit)\n",
        "\n",
        "  return models[best_model].fit(X, y)"
      ],
      "metadata": {
        "id": "xwi4yUN9X95V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_crossvalidate_clf(df, label, k=10, n=5, repeat=True):\n",
        "  import sklearn.linear_model as lm, sklearn.ensemble as en\n",
        "  from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score\n",
        "  import pandas as pd\n",
        "  from numpy import mean, std\n",
        "  # from xgboost import XGBClassifier\n",
        "\n",
        "  X = df.drop(columns=[label])\n",
        "  y = df[label]\n",
        "\n",
        "  if repeat:\n",
        "    cv = RepeatedKFold(n_splits=k, n_repeats=n, random_state=12345)\n",
        "  else:\n",
        "    cv = KFold(n_splits=k, random_state=12345, shuffle=True)\n",
        "\n",
        "  fit = {}\n",
        "  models = {}\n",
        "\n",
        "  # model_mlr = lm.LogisticRegression()\n",
        "  model_gradientboost = en.GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
        "  model_ridge = lm.RidgeClassifier()\n",
        "  model_ada = en.AdaBoostClassifier(random_state=0, n_estimators=100)\n",
        "  model_ext = en.ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
        "  model_randomforest = en.RandomForestClassifier(n_estimators=1000, max_depth=7)\n",
        "\n",
        "  fit['GradientBoost'] = mean(cross_val_score(model_gradientboost, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
        "  fit['Ridge'] = mean(cross_val_score(model_ridge, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
        "  fit['AdaBoost'] = mean(cross_val_score(model_ada, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
        "  fit['ExtraTrees'] = mean(cross_val_score(model_ext, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
        "  fit['RandomForest'] = mean(cross_val_score(model_randomforest, X, y, scoring='accuracy', cv=cv, n_jobs=-1))\n",
        "\n",
        "  models['GradientBoost'] = model_gradientboost\n",
        "  models['Ridge'] = model_ridge\n",
        "  models['AdaBoost'] = model_ada\n",
        "  models['ExtraTrees'] = model_ext\n",
        "  models['RandomForest'] = model_randomforest\n",
        "\n",
        "  df_fit = pd.DataFrame({'Accuracy':fit})\n",
        "  df_fit.sort_values(by=['Accuracy'], ascending=False, inplace=True)\n",
        "  best_model = df_fit.index[0]\n",
        "  print(df_fit)\n",
        "\n",
        "  return models[best_model].fit(X, y)"
      ],
      "metadata": {
        "id": "6wWTwYnmK4YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_low_skew(df, label):\n",
        "  import numpy as np\n",
        "\n",
        "  # 0 is normal, 1 is square root, 2 is cube root, 3 is regular log, 4 is log1p\n",
        "\n",
        "  skew_list = []\n",
        "  f_label = label\n",
        "\n",
        "  skew = df[f_label].skew()\n",
        "  print(\"Regular Skew: \", skew)\n",
        "  skew_list.append(skew)\n",
        "\n",
        "  square_root = (df[f_label]**(1/2)).skew()\n",
        "  print(\"Square Root Skew: \", square_root)\n",
        "  skew_list.append(square_root)\n",
        "\n",
        "  cube_root = (df[f_label]**(1/3)).skew()\n",
        "  print(\"Cube Root Skew: \", cube_root)\n",
        "  skew_list.append(cube_root)\n",
        "\n",
        "  print(\"Regular Log Skew: \", np.log(df[f_label]).skew())\n",
        "  skew_list.append(np.log(df[f_label]).skew())\n",
        "  \n",
        "  print(\"Log1P Skew: \", np.log1p(df[f_label]).skew())\n",
        "  skew_list.append(np.log1p(df[f_label]).skew())\n",
        "\n",
        "  x = max(skew_list)\n",
        "\n",
        "  for count, item in enumerate(skew_list):\n",
        "    if(item < x):\n",
        "      x = item\n",
        "      y = count\n",
        "  \n",
        "  new_df = df.copy()\n",
        "\n",
        "  print('This is y  ', y)\n",
        "\n",
        "  if y == 0:\n",
        "    new_df[f_label] = df[f_label]\n",
        "  elif y == 1:\n",
        "    new_df[f_label] = (df[f_label]**(1/2))\n",
        "  elif y == 2:\n",
        "    new_df[f_label] = (df[f_label]**(1/3))\n",
        "  elif y == 3:\n",
        "    new_df[f_label] = np.log(df[f_label])\n",
        "  elif y == 4:\n",
        "    new_df[f_label] = np.log1p(df[f_label])\n",
        "\n",
        "  return new_df"
      ],
      "metadata": {
        "id": "h-4rI1I0cvHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def revert_from_skew(df, label, skew_num = 0):\n",
        "  import numpy as np\n",
        "\n",
        "  reverted_df = df.copy()\n",
        "\n",
        "  if skew_num == 1:\n",
        "    reverted_df[label] = (reverted_df[label]**(2))\n",
        "  elif skew_num == 2:\n",
        "    reverted_df[label] = (reverted_df[label]**(3))\n",
        "  elif skew_num == 3:\n",
        "    reverted_df[label] = np.exp(reverted_df[label])\n",
        "  elif skew_num == 4:\n",
        "    reverted_df[label] = mp.exp(reverted_df[label])\n",
        "    reverted_df[label] = reverted_df[label] - 1\n",
        "\n",
        "  return reverted_df"
      ],
      "metadata": {
        "id": "8Re4KifpgHTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_df(df):\n",
        "  import requests\n",
        "  import json\n",
        "  import pandas as pd\n",
        "  import time\n",
        "  # df = pd.read_csv(\"/content/final_csv.csv\")\n",
        "  # df = df[df['photos'].str.contains('google') == False]\n",
        "\n",
        "  api_key = 'acc_0d509e4a712c933'\n",
        "  api_secret = 'c8ffba881a181db58c8ea9a39f67ed9f'\n",
        "  authorization = 'Basic YWNjXzBkNTA5ZTRhNzEyYzkzMzpiODYzZmYzMDI4MGE5NmFkZWQ0YjViNzJiM2Y3MzE3Nw=='\n",
        "  endpoint = 'https://api.imagga.com'\n",
        "\n",
        "  df_img = pd.DataFrame(columns=['fence', 'grass', 'housing', 'house', 'home', 'architecture', 'building', 'tree', 'roof', 'lawn', 'window', 'brick',\n",
        "                            'garage', 'windows', 'modern', 'bungalow', 'door'])\n",
        "\n",
        "  url = 'https://api.imagga.com/v2/tags/?image_url=https://photos.zillowstatic.com/fp/'\n",
        "\n",
        "  images = {}\n",
        "  for i in df.itertuples():\n",
        "  # for item in df.itertuples():\n",
        "    images[i[0]] = i[8][35:]\n",
        "\n",
        "  # Not testing anymore\n",
        "  for count, i in enumerate(df.itertuples()):\n",
        "    request = requests.get(url + images[i[0]], auth=(api_key, api_secret))\n",
        "  ## Replace these two lines for the real run\n",
        "  # for image in images: \n",
        "  #   request = requests.get(url + image, auth=(api_key, api_secret))\n",
        "    json_data = json.loads(request.text)\n",
        "    # print(json.dumps(json_data, indent=2))\n",
        "\n",
        "    # Create a list of 0.0 scores to update as we get data for each category we want to score in our DataFrame\n",
        "    scores = [0.0] * len(df_img.columns)\n",
        "\n",
        "    # Iterate through each category of the result\n",
        "    for category in json_data[\"result\"][\"tags\"]:\n",
        "      # Find the associated column in the DataFrame\n",
        "      for n, col in enumerate(df_img.columns):\n",
        "        if col == category['tag']['en']:\n",
        "          # Store the score\n",
        "          scores[n] = category['confidence']\n",
        "          break # No need to keep looping once we've found the score\n",
        "\n",
        "      # Store the list as a new row in the DataFrame\n",
        "      df_img.loc[list(images.keys())[list(images.values()).index(i[8][35:])]] = scores\n",
        "      #df_img.loc[image] = scores\n",
        "\n",
        "    time.sleep(3)\n",
        "\n",
        "    if count % 10 == 0:\n",
        "      print('Processed ', count, ' images')\n",
        "\n",
        "  df = df.merge(df_img, left_index=True, right_index=True)\n",
        "  df.drop(columns=['photos'], inplace=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "Iryw2Uum5rzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_sentiment(df):\n",
        "  import nltk\n",
        "  from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "  nltk.download('vader_lexicon')\n",
        "  sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "  sentiment_df = df.copy()\n",
        "\n",
        "  sentiment_df['sentiment_overall'] = 0.0\n",
        "  sentiment_df['sentiment_neg'] = 0.0\n",
        "  sentiment_df['sentiment_neu'] = 0.0\n",
        "  sentiment_df['sentiment_pos'] = 0.0\n",
        "    \n",
        "  for row in sentiment_df.itertuples():\n",
        "    sentiment = sia.polarity_scores(row[7])\n",
        "    sentiment_df.loc[row[0], 'sentiment_overall'] = sentiment['compound']\n",
        "    sentiment_df.loc[row[0], 'sentiment_neg'] = sentiment['neg']\n",
        "    sentiment_df.loc[row[0], 'sentiment_neu'] = sentiment['neu']\n",
        "    sentiment_df.loc[row[0], 'sentiment_pos'] = sentiment['pos']\n",
        "\n",
        "  return sentiment_df"
      ],
      "metadata": {
        "id": "apVDX_kR6-k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dump_pickle(model, file_name):\n",
        "  import pickle\n",
        "  pickle.dump(model, open(file_name, \"wb\"))\n",
        "\n",
        "def load_pickle(file_name):\n",
        "  import pickle\n",
        "  model = pickle.load(open(file_name, \"rb\"))\n",
        "  return model"
      ],
      "metadata": {
        "id": "ZsY1RncXDbQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ch_criterion(df):\n",
        "  from sklearn.metrics import calinski_harabasz_score\n",
        "  from matplotlib import pyplot as plt\n",
        "  from sklearn.cluster import KMeans\n",
        "\n",
        "  ch_score = []\n",
        "  for n in range(2, 21):\n",
        "    kmeans = KMeans(n, random_state=12345).fit(df)\n",
        "    ch_score.append(calinski_harabasz_score(df, labels=kmeans.labels_))\n",
        "\n",
        "  plt.plot(range(2, 21), ch_score, 'bx-')\n",
        "  plt.xlabel('number of clusters') \n",
        "  plt.ylabel('Calinski_Harabasz Criterion') \n",
        "  plt.title('Optimal Number of Clusters')\n",
        "  plt.text(12, 40, 'Higher is better', bbox=dict(facecolor='red', alpha=0.5))\n",
        "  return(plt.show())"
      ],
      "metadata": {
        "id": "WXaWNbtioiKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def silhouette_analysis(df):\n",
        "  from sklearn.metrics import silhouette_score\n",
        "  from sklearn.cluster import KMeans\n",
        "\n",
        "  si_score = []\n",
        "  for n in range(2, 21):\n",
        "    kmeans = KMeans(n, random_state=12345).fit(df)\n",
        "    si_score.append(silhouette_score(df, kmeans.labels_))\n",
        "\n",
        "  plt.plot(range(2, 21), si_score, 'bx-')\n",
        "  plt.xlabel('number of clusters') \n",
        "  plt.ylabel('Silhouette score') \n",
        "  plt.title('Optimal Number of Clusters')\n",
        "  plt.text(11, .14, 'Higher is better', bbox=dict(facecolor='red', alpha=0.5))\n",
        "  return(plt.show())"
      ],
      "metadata": {
        "id": "B8hQdj52ozDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def elbow_method(df):\n",
        "  from sklearn.cluster import KMeans\n",
        "  ss_score = []\n",
        "  for n in range(2,11):\n",
        "      kmeans = KMeans(n, random_state=12345).fit(df)\n",
        "      ss_score.append(kmeans.inertia_)\n",
        "      \n",
        "  # Where does the slope bend? Find the highest (least negative) slope.\n",
        "  changes = []\n",
        "  for n in range(2, 10):\n",
        "    changes.append(float(ss_score[n - 1] - ss_score[n - 2]))\n",
        "\n",
        "  optimal_n = changes.index(max(changes))\n",
        "\n",
        "  plt.plot(range(2,11), ss_score, 'bx-', markevery=[optimal_n])\n",
        "  plt.xlabel('number of clusters')\n",
        "  plt.ylabel('SS distance')\n",
        "  plt.title('Optimal Number of Clusters')\n",
        "  plt.text(8, 900, 'The point where slope \"bends\" from a \\ndecreasing to increasing rate of change', bbox=dict(facecolor='red', alpha=0.5))\n",
        "  return(plt.show())"
      ],
      "metadata": {
        "id": "EfQY5HWmooWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_top_features(df_wcluster):\n",
        "  output_df = pd.DataFrame({'C0_means': df_wcluster[df_wcluster.cluster == 0].mean(), 'C1_means': df_wcluster[df_wcluster.cluster == 1].mean()})\n",
        "  output_df['diff'] = abs(output_df['C0_means'] - output_df['C1_means'])\n",
        "  return(output_df.drop(['cluster']).sort_values(by=['diff'], ascending=False))"
      ],
      "metadata": {
        "id": "aVLYbs5MopDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "teESyxWBo67L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO\n",
        "from IPython.display import Image  \n",
        "import pydotplus, six\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def decision_tree(df):\n",
        "  df_tree = df.copy() \n",
        "  df_tree.fillna(0,inplace=True)\n",
        "\n",
        "  df_tree['zipcode'] = df_tree['zipcode'].apply(str)\n",
        "  df_tree['yearBuilt'] = df_tree['yearBuilt'].apply(str)\n",
        "\n",
        "  # df_tree.drop(columns=['description'])\n",
        "\n",
        "  for col in df_tree:\n",
        "    if not pd.api.types.is_numeric_dtype(df_tree[col]):\n",
        "      df_tree = df_tree.join(pd.get_dummies(df_tree[col], prefix=col))\n",
        "  \n",
        "  y = df_tree['zipcode'] # Label\n",
        "  X = df_tree\n",
        "  X = X.select_dtypes(np.number)\n",
        "\n",
        "  # Create Decision Tree classifer object\n",
        "  clf = DecisionTreeClassifier()\n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345) # 70% training and 30% test\n",
        "\n",
        "  # Train Decision Tree Classifer\n",
        "  clf = clf.fit(X_train,y_train)\n",
        "\n",
        "  # Predict the labels for test dataset\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  # View the predicted versus actual in a DataFrame\n",
        "  output_df = pd.DataFrame({'Actual Zip Code': y_test, 'Predicted Zip Code': y_pred,})\n",
        "  \n",
        "  print(output_df.head(30))\n",
        "\n",
        "  # Accuracy  = (true positives + true negatives) / (total cases); ranges from 0 (worst) to 1 (best)\n",
        "  print(f\"Accuracy:\\t{metrics.accuracy_score(y_test, y_pred)}\")\n"
      ],
      "metadata": {
        "id": "PawhZENgH8RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "br0r5x1YXS55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> # Data Prep/Cleaning"
      ],
      "metadata": {
        "id": "x-gLwkizljoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = get_dataframe()\n",
        "\n",
        "# df = pd.read_csv(\"/content/final_csv.csv\")\n",
        "\n",
        "df = clean_data(df)\n",
        "\n",
        "df.fillna(0, inplace = True)\n",
        "df.drop(columns = ['id'], inplace = True)\n",
        "\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "oEE5C3CCEh9D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d94c0edc-fed7-43a5-81aa-1ddd2997dff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>price</th>\n",
              "      <th>yearBuilt</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>description</th>\n",
              "      <th>livingArea</th>\n",
              "      <th>photos</th>\n",
              "      <th>city</th>\n",
              "      <th>zipcode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>325000</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>-113.627525</td>\n",
              "      <td>37.419490</td>\n",
              "      <td>Incredible buy on a cozy A-frame cabin just mi...</td>\n",
              "      <td>1792.0</td>\n",
              "      <td>https://photos.zillowstatic.com/fp/e7770beea52...</td>\n",
              "      <td>Central</td>\n",
              "      <td>84722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>299000</td>\n",
              "      <td>1914.0</td>\n",
              "      <td>-111.708940</td>\n",
              "      <td>39.113277</td>\n",
              "      <td>Great family home with 4 bedrooms and 1.5 bath...</td>\n",
              "      <td>2100.0</td>\n",
              "      <td>https://photos.zillowstatic.com/fp/23f901bbeb8...</td>\n",
              "      <td>Mayfield</td>\n",
              "      <td>84643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>549000</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>-113.091545</td>\n",
              "      <td>37.748530</td>\n",
              "      <td>Gorgeous Four Bedroom Home in a wonderful neig...</td>\n",
              "      <td>3404.0</td>\n",
              "      <td>https://photos.zillowstatic.com/fp/44275f6a116...</td>\n",
              "      <td>Cedar City</td>\n",
              "      <td>84721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>465000</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>-113.542490</td>\n",
              "      <td>37.107285</td>\n",
              "      <td>Looking for the perfect brick home at the end ...</td>\n",
              "      <td>1920.0</td>\n",
              "      <td>https://photos.zillowstatic.com/fp/c11ab4b7dec...</td>\n",
              "      <td>Saint George</td>\n",
              "      <td>84790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>425000</td>\n",
              "      <td>1940.0</td>\n",
              "      <td>-111.872950</td>\n",
              "      <td>40.720016</td>\n",
              "      <td>ALL OFFERS WILL BE RESPONDED TO BY FRIDAY DECE...</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>https://photos.zillowstatic.com/fp/8c95be96547...</td>\n",
              "      <td>Salt Lake City</td>\n",
              "      <td>84106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     bedrooms  bathrooms  ...            city  zipcode\n",
              "531       3.0        2.0  ...         Central    84722\n",
              "451       4.0        2.0  ...        Mayfield    84643\n",
              "845       4.0        2.0  ...      Cedar City    84721\n",
              "15        4.0        3.0  ...    Saint George    84790\n",
              "493       3.0        1.0  ...  Salt Lake City    84106\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = add_sentiment(df)"
      ],
      "metadata": {
        "id": "-MT6DLYo8JKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c5fa681-5192-44db-f30d-e6cc439ceacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = scored_text_df(df, 'description', num_topics = 5, stop_list = ['home', 'room', 'bedroom', 'large', \n",
        "                                                    'kitchen', 'great', 'storage', 'new', \n",
        "                                                    'include', 'family', 'area', 'walk', \n",
        "                                                    'space', 'view', 'mountain', 'offer', \n",
        "                                                    'acre', 'also', 'bath', 'property', \n",
        "                                                    'beautiful', 'bathroom', 'feature', \n",
        "                                                    'live', 'locate', 'enjoy', 'basement'])"
      ],
      "metadata": {
        "id": "KejYXLPJdNvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e67ac3-3821-49d6-e73c-21d66a7f3707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = image_df(df)"
      ],
      "metadata": {
        "id": "f3TlLl9MoVhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "024a49e6-de3d-4cc6-fe46-b5c33b43d9d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed  0  images\n",
            "Processed  10  images\n",
            "Processed  20  images\n",
            "Processed  30  images\n",
            "Processed  40  images\n",
            "Processed  50  images\n",
            "Processed  60  images\n",
            "Processed  70  images\n",
            "Processed  80  images\n",
            "Processed  90  images\n",
            "Processed  100  images\n",
            "Processed  110  images\n",
            "Processed  120  images\n",
            "Processed  130  images\n",
            "Processed  140  images\n",
            "Processed  150  images\n",
            "Processed  160  images\n",
            "Processed  170  images\n",
            "Processed  180  images\n",
            "Processed  190  images\n",
            "Processed  200  images\n",
            "Processed  210  images\n",
            "Processed  220  images\n",
            "Processed  230  images\n",
            "Processed  240  images\n",
            "Processed  250  images\n",
            "Processed  260  images\n",
            "Processed  270  images\n",
            "Processed  280  images\n",
            "Processed  290  images\n",
            "Processed  300  images\n",
            "Processed  310  images\n",
            "Processed  320  images\n",
            "Processed  330  images\n",
            "Processed  340  images\n",
            "Processed  350  images\n",
            "Processed  360  images\n",
            "Processed  370  images\n",
            "Processed  380  images\n",
            "Processed  390  images\n",
            "Processed  400  images\n",
            "Processed  410  images\n",
            "Processed  420  images\n",
            "Processed  430  images\n",
            "Processed  440  images\n",
            "Processed  450  images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_regression = df.copy()\n",
        "\n",
        "df_regression = find_low_skew(df_regression, 'price')\n",
        "\n",
        "df_regression = dummy_code_df(df_regression.drop(columns = ['city']))"
      ],
      "metadata": {
        "id": "smecequboVxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16885340-8641-4682-d4d3-3e095ae2151f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regular Skew:  4.222113289748103\n",
            "Square Root Skew:  2.2484479812122777\n",
            "Cube Root Skew:  1.7448950156846823\n",
            "Regular Log Skew:  0.7696076551606159\n",
            "Log1P Skew:  0.7696129290824678\n",
            "This is y   3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> # Data Modeling"
      ],
      "metadata": {
        "id": "N-EW6m3Wl1x8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">> # Regression"
      ],
      "metadata": {
        "id": "K0aXY06fKp6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vif_df = vif(df_regression.drop(columns = 'price'))\n",
        "\n",
        "while vif_df['VIF'].max() > 10:\n",
        "  df_regression.drop(columns = [vif_df['VIF'].idxmax()], inplace = True)\n",
        "  vif_df = vif(df_regression)\n",
        "\n",
        "vif_df"
      ],
      "metadata": {
        "id": "UWvmeAsFl42n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "533a44a9-7c36-489d-bce3-44ff0d6847cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VIF</th>\n",
              "      <th>Tolerance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bedrooms</th>\n",
              "      <td>3.066528</td>\n",
              "      <td>0.326102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bathrooms</th>\n",
              "      <td>6.418835</td>\n",
              "      <td>0.155791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>3.804488</td>\n",
              "      <td>0.262847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yearBuilt</th>\n",
              "      <td>1.083960</td>\n",
              "      <td>0.922544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>longitude</th>\n",
              "      <td>2.537042</td>\n",
              "      <td>0.394160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>latitude</th>\n",
              "      <td>5.746599</td>\n",
              "      <td>0.174016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>livingArea</th>\n",
              "      <td>5.189421</td>\n",
              "      <td>0.192700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zipcode</th>\n",
              "      <td>5.924788</td>\n",
              "      <td>0.168782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_overall</th>\n",
              "      <td>1.980152</td>\n",
              "      <td>0.505012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_neg</th>\n",
              "      <td>1.336742</td>\n",
              "      <td>0.748087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_neu</th>\n",
              "      <td>1.767950</td>\n",
              "      <td>0.565627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_1</th>\n",
              "      <td>1.531190</td>\n",
              "      <td>0.653087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_2</th>\n",
              "      <td>1.261373</td>\n",
              "      <td>0.792787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_3</th>\n",
              "      <td>2.028049</td>\n",
              "      <td>0.493085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_4</th>\n",
              "      <td>1.451101</td>\n",
              "      <td>0.689132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fence</th>\n",
              "      <td>1.189232</td>\n",
              "      <td>0.840879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>grass</th>\n",
              "      <td>4.140153</td>\n",
              "      <td>0.241537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>housing</th>\n",
              "      <td>1.603302</td>\n",
              "      <td>0.623713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>architecture</th>\n",
              "      <td>5.885484</td>\n",
              "      <td>0.169910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>building</th>\n",
              "      <td>2.150352</td>\n",
              "      <td>0.465040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tree</th>\n",
              "      <td>1.932346</td>\n",
              "      <td>0.517506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>roof</th>\n",
              "      <td>3.314976</td>\n",
              "      <td>0.301661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lawn</th>\n",
              "      <td>7.734793</td>\n",
              "      <td>0.129286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>window</th>\n",
              "      <td>3.438766</td>\n",
              "      <td>0.290802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brick</th>\n",
              "      <td>4.434299</td>\n",
              "      <td>0.225515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>garage</th>\n",
              "      <td>1.934333</td>\n",
              "      <td>0.516974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>windows</th>\n",
              "      <td>9.171008</td>\n",
              "      <td>0.109039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modern</th>\n",
              "      <td>4.272226</td>\n",
              "      <td>0.234070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bungalow</th>\n",
              "      <td>2.267093</td>\n",
              "      <td>0.441093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>door</th>\n",
              "      <td>5.399761</td>\n",
              "      <td>0.185193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        VIF  Tolerance\n",
              "bedrooms           3.066528   0.326102\n",
              "bathrooms          6.418835   0.155791\n",
              "price              3.804488   0.262847\n",
              "yearBuilt          1.083960   0.922544\n",
              "longitude          2.537042   0.394160\n",
              "latitude           5.746599   0.174016\n",
              "livingArea         5.189421   0.192700\n",
              "zipcode            5.924788   0.168782\n",
              "sentiment_overall  1.980152   0.505012\n",
              "sentiment_neg      1.336742   0.748087\n",
              "sentiment_neu      1.767950   0.565627\n",
              "topic_1            1.531190   0.653087\n",
              "topic_2            1.261373   0.792787\n",
              "topic_3            2.028049   0.493085\n",
              "topic_4            1.451101   0.689132\n",
              "fence              1.189232   0.840879\n",
              "grass              4.140153   0.241537\n",
              "housing            1.603302   0.623713\n",
              "architecture       5.885484   0.169910\n",
              "building           2.150352   0.465040\n",
              "tree               1.932346   0.517506\n",
              "roof               3.314976   0.301661\n",
              "lawn               7.734793   0.129286\n",
              "window             3.438766   0.290802\n",
              "brick              4.434299   0.225515\n",
              "garage             1.934333   0.516974\n",
              "windows            9.171008   0.109039\n",
              "modern             4.272226   0.234070\n",
              "bungalow           2.267093   0.441093\n",
              "door               5.399761   0.185193"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = fit_crossvalidate_reg(df_regression, 'price')"
      ],
      "metadata": {
        "id": "r9GKPFgrnT2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1153e769-6fa5-408e-8285-89a9d66185fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             R-squared\n",
            "XGBoost       0.784072\n",
            "HG Boost      0.783157\n",
            "Grad. Boost   0.775807\n",
            "Voting        0.761593\n",
            "Dec Forest    0.742329\n",
            "Extra Trees   0.741286\n",
            "AdaBoost DT   0.698028\n",
            "Stacking      0.648642\n",
            "OLS           0.528529\n",
            "Ridge         0.518136\n",
            "GaussianP     0.502171\n",
            "Bayesian      0.464989\n",
            "SupportVM     0.228538\n",
            "Lasso         0.222877\n",
            "NuSupportVM   0.207231\n",
            "LARS         -0.034099\n",
            "Inverse      -0.034099\n",
            "Poisson      -0.034099\n",
            "Gamma        -0.034099\n",
            "Linear SVM   -0.090254\n",
            "[02:01:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dumps into a sav\n",
        "\n",
        "dump_pickle(model, 'saved_model_regression.sav')"
      ],
      "metadata": {
        "id": "wN-zjzhwDJ4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Should you buy\n",
        "\n",
        "# Load model from sav file\n",
        "model = load_pickle('/content/saved_model_regression.sav')\n",
        "\n",
        "# Ensure proper rounding\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "\n",
        "# Create dataframe with predicted and acutal values\n",
        "buy_df = pd.DataFrame({'Actual': df['price'], 'Predicted': model.predict(df_regression.drop(columns = ['price']))})\n",
        "\n",
        "# Convert prediction (changed when adjusting for skew)\n",
        "buy_df['Predicted'] = np.exp(buy_df['Predicted'])\n",
        "\n",
        "# Column that tells you whether or not you should buy the property\n",
        "buy_df['Buy?'] = np.where(buy_df.Actual > buy_df.Predicted, 'Buy', 'Don\\'t Buy')\n",
        "\n",
        "buy_df"
      ],
      "metadata": {
        "id": "fhfNbhffDvS0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "c15dc18a-2aa1-4ba0-e2ef-3a11a5ea857e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:01:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Buy?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>325000</td>\n",
              "      <td>324981.19</td>\n",
              "      <td>Buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>299000</td>\n",
              "      <td>298990.09</td>\n",
              "      <td>Buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>549000</td>\n",
              "      <td>548969.12</td>\n",
              "      <td>Buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>465000</td>\n",
              "      <td>465268.62</td>\n",
              "      <td>Don't Buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>425000</td>\n",
              "      <td>424932.75</td>\n",
              "      <td>Buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>586</th>\n",
              "      <td>299900</td>\n",
              "      <td>299883.91</td>\n",
              "      <td>Buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>239000</td>\n",
              "      <td>239052.75</td>\n",
              "      <td>Don't Buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>529000</td>\n",
              "      <td>528906.00</td>\n",
              "      <td>Buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>976</th>\n",
              "      <td>2200000</td>\n",
              "      <td>2201183.00</td>\n",
              "      <td>Don't Buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>127000</td>\n",
              "      <td>127124.59</td>\n",
              "      <td>Don't Buy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>457 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Actual  Predicted       Buy?\n",
              "531   325000  324981.19        Buy\n",
              "451   299000  298990.09        Buy\n",
              "845   549000  548969.12        Buy\n",
              "15    465000  465268.62  Don't Buy\n",
              "493   425000  424932.75        Buy\n",
              "..       ...        ...        ...\n",
              "586   299900  299883.91        Buy\n",
              "5     239000  239052.75  Don't Buy\n",
              "245   529000  528906.00        Buy\n",
              "976  2200000 2201183.00  Don't Buy\n",
              "326   127000  127124.59  Don't Buy\n",
              "\n",
              "[457 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">> # Classification"
      ],
      "metadata": {
        "id": "Jv0OM7hrLum_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_classification = df.copy()\n",
        "\n",
        "df_classification = dummy_code_df(df_classification.drop(columns = ['city']))\n",
        "df_classification['city'] = df.city\n",
        "classification_model = fit_crossvalidate_clf(df_classification, 'city')"
      ],
      "metadata": {
        "id": "hdOfRUQmLxsM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb1fd790-c6c2-4ed7-e55f-f17f726f7867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Accuracy\n",
            "GradientBoost      0.53\n",
            "ExtraTrees         0.50\n",
            "RandomForest       0.46\n",
            "Ridge              0.25\n",
            "AdaBoost           0.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dumps into a sav\n",
        "dump_pickle(model, 'saved_model_classification.sav')"
      ],
      "metadata": {
        "id": "XaKayT6bBFqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree(df)"
      ],
      "metadata": {
        "id": "sgkbn_XOmfqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c270a18e-12c9-4730-f41f-fa08b0dd395e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Actual Zip Code Predicted Zip Code\n",
            "366           84036              84036\n",
            "454           84035              84027\n",
            "905           84074              84074\n",
            "444           84335              84535\n",
            "186           84032              84032\n",
            "963           84029              84121\n",
            "580           84780              84780\n",
            "155           84663              84663\n",
            "139           84001              84651\n",
            "389           84770              84770\n",
            "625           84790              84790\n",
            "396           84770              84770\n",
            "176           84055              84055\n",
            "872           84770              84770\n",
            "446           84078              84078\n",
            "202           84629              84001\n",
            "707           84401              84401\n",
            "687           84790              84790\n",
            "245           84028              84028\n",
            "360           84078              84078\n",
            "696           84737              84737\n",
            "443           84055              84055\n",
            "534           84078              84078\n",
            "918           84780              84780\n",
            "600           84106              84629\n",
            "55            84720              84720\n",
            "839           84735              84620\n",
            "115           84036              84036\n",
            "849           84118              84118\n",
            "682           84078              84078\n",
            "Accuracy:\t0.7753623188405797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">> # Clustering"
      ],
      "metadata": {
        "id": "IH2tWnQ5VKi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bin = df.copy()\n",
        "\n",
        "for col in df_bin:\n",
        "    if col in ['yearBuilt', 'zipcode', 'city']:\n",
        "        for group, count in df_bin[col].value_counts().iteritems():\n",
        "            if count / len(df) < 0.01:\n",
        "                df_bin.loc[df_bin[col] == group, col] = 'Other'"
      ],
      "metadata": {
        "id": "KtK_ejasVeZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dummies = df_bin.copy()\n",
        "df_dummies = pd.get_dummies(df_dummies, columns=['yearBuilt', 'zipcode', 'city'])\n",
        "df_dummies = df_dummies.select_dtypes(['number'])\n",
        "df_dummies"
      ],
      "metadata": {
        "id": "zX5at4q0VlA8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "b9610061-cd85-4a70-b826-da1fbf97459e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>price</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>livingArea</th>\n",
              "      <th>sentiment_overall</th>\n",
              "      <th>sentiment_neg</th>\n",
              "      <th>sentiment_neu</th>\n",
              "      <th>sentiment_pos</th>\n",
              "      <th>topic_1</th>\n",
              "      <th>topic_2</th>\n",
              "      <th>topic_3</th>\n",
              "      <th>topic_4</th>\n",
              "      <th>topic_5</th>\n",
              "      <th>fence</th>\n",
              "      <th>grass</th>\n",
              "      <th>housing</th>\n",
              "      <th>house</th>\n",
              "      <th>home</th>\n",
              "      <th>architecture</th>\n",
              "      <th>building</th>\n",
              "      <th>tree</th>\n",
              "      <th>roof</th>\n",
              "      <th>lawn</th>\n",
              "      <th>window</th>\n",
              "      <th>brick</th>\n",
              "      <th>garage</th>\n",
              "      <th>windows</th>\n",
              "      <th>modern</th>\n",
              "      <th>bungalow</th>\n",
              "      <th>door</th>\n",
              "      <th>yearBuilt_1956.0</th>\n",
              "      <th>yearBuilt_1976.0</th>\n",
              "      <th>yearBuilt_1978.0</th>\n",
              "      <th>yearBuilt_1980.0</th>\n",
              "      <th>yearBuilt_1982.0</th>\n",
              "      <th>yearBuilt_1983.0</th>\n",
              "      <th>yearBuilt_1984.0</th>\n",
              "      <th>yearBuilt_1985.0</th>\n",
              "      <th>...</th>\n",
              "      <th>zipcode_84060</th>\n",
              "      <th>zipcode_84066</th>\n",
              "      <th>zipcode_84074</th>\n",
              "      <th>zipcode_84078</th>\n",
              "      <th>zipcode_84098</th>\n",
              "      <th>zipcode_84501</th>\n",
              "      <th>zipcode_84532</th>\n",
              "      <th>zipcode_84647</th>\n",
              "      <th>zipcode_84720</th>\n",
              "      <th>zipcode_84721</th>\n",
              "      <th>zipcode_84737</th>\n",
              "      <th>zipcode_84745</th>\n",
              "      <th>zipcode_84770</th>\n",
              "      <th>zipcode_84780</th>\n",
              "      <th>zipcode_84790</th>\n",
              "      <th>zipcode_Other</th>\n",
              "      <th>city_Cedar City</th>\n",
              "      <th>city_Eagle Mountain</th>\n",
              "      <th>city_Garden City</th>\n",
              "      <th>city_Heber City</th>\n",
              "      <th>city_Hurricane</th>\n",
              "      <th>city_Kamas</th>\n",
              "      <th>city_La Verkin</th>\n",
              "      <th>city_Lehi</th>\n",
              "      <th>city_Midway</th>\n",
              "      <th>city_Moab</th>\n",
              "      <th>city_Mount Pleasant</th>\n",
              "      <th>city_Ogden</th>\n",
              "      <th>city_Orem</th>\n",
              "      <th>city_Other</th>\n",
              "      <th>city_Park City</th>\n",
              "      <th>city_Price</th>\n",
              "      <th>city_Provo</th>\n",
              "      <th>city_Roosevelt</th>\n",
              "      <th>city_Saint George</th>\n",
              "      <th>city_Salt Lake City</th>\n",
              "      <th>city_South Jordan</th>\n",
              "      <th>city_St George</th>\n",
              "      <th>city_Vernal</th>\n",
              "      <th>city_Washington</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>3.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>325000</td>\n",
              "      <td>-113.63</td>\n",
              "      <td>37.42</td>\n",
              "      <td>1792.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>19.03</td>\n",
              "      <td>16.71</td>\n",
              "      <td>64.55</td>\n",
              "      <td>54.41</td>\n",
              "      <td>43.92</td>\n",
              "      <td>33.75</td>\n",
              "      <td>14.66</td>\n",
              "      <td>27.78</td>\n",
              "      <td>17.02</td>\n",
              "      <td>12.12</td>\n",
              "      <td>29.91</td>\n",
              "      <td>72.21</td>\n",
              "      <td>21.19</td>\n",
              "      <td>16.88</td>\n",
              "      <td>16.16</td>\n",
              "      <td>16.22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>4.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>299000</td>\n",
              "      <td>-111.71</td>\n",
              "      <td>39.11</td>\n",
              "      <td>2100.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13.47</td>\n",
              "      <td>90.12</td>\n",
              "      <td>72.04</td>\n",
              "      <td>59.17</td>\n",
              "      <td>46.33</td>\n",
              "      <td>32.14</td>\n",
              "      <td>11.56</td>\n",
              "      <td>22.94</td>\n",
              "      <td>15.12</td>\n",
              "      <td>16.52</td>\n",
              "      <td>19.82</td>\n",
              "      <td>44.25</td>\n",
              "      <td>21.18</td>\n",
              "      <td>18.98</td>\n",
              "      <td>77.32</td>\n",
              "      <td>24.03</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>4.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>549000</td>\n",
              "      <td>-113.09</td>\n",
              "      <td>37.75</td>\n",
              "      <td>3404.00</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>22.97</td>\n",
              "      <td>19.05</td>\n",
              "      <td>68.74</td>\n",
              "      <td>64.72</td>\n",
              "      <td>55.66</td>\n",
              "      <td>40.11</td>\n",
              "      <td>13.87</td>\n",
              "      <td>23.60</td>\n",
              "      <td>22.66</td>\n",
              "      <td>17.60</td>\n",
              "      <td>40.28</td>\n",
              "      <td>47.28</td>\n",
              "      <td>25.97</td>\n",
              "      <td>21.77</td>\n",
              "      <td>35.24</td>\n",
              "      <td>20.46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>465000</td>\n",
              "      <td>-113.54</td>\n",
              "      <td>37.11</td>\n",
              "      <td>1920.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.00</td>\n",
              "      <td>8.41</td>\n",
              "      <td>23.76</td>\n",
              "      <td>12.02</td>\n",
              "      <td>49.84</td>\n",
              "      <td>40.75</td>\n",
              "      <td>43.39</td>\n",
              "      <td>77.45</td>\n",
              "      <td>22.31</td>\n",
              "      <td>15.39</td>\n",
              "      <td>20.78</td>\n",
              "      <td>12.18</td>\n",
              "      <td>20.90</td>\n",
              "      <td>11.36</td>\n",
              "      <td>15.39</td>\n",
              "      <td>14.05</td>\n",
              "      <td>15.13</td>\n",
              "      <td>13.34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>3.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>425000</td>\n",
              "      <td>-111.87</td>\n",
              "      <td>40.72</td>\n",
              "      <td>1100.00</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>7.26</td>\n",
              "      <td>19.05</td>\n",
              "      <td>26.08</td>\n",
              "      <td>73.85</td>\n",
              "      <td>67.25</td>\n",
              "      <td>55.94</td>\n",
              "      <td>40.47</td>\n",
              "      <td>12.42</td>\n",
              "      <td>26.50</td>\n",
              "      <td>22.71</td>\n",
              "      <td>15.80</td>\n",
              "      <td>34.16</td>\n",
              "      <td>46.43</td>\n",
              "      <td>25.05</td>\n",
              "      <td>24.63</td>\n",
              "      <td>100.00</td>\n",
              "      <td>22.06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>586</th>\n",
              "      <td>3.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>299900</td>\n",
              "      <td>-110.98</td>\n",
              "      <td>39.34</td>\n",
              "      <td>1850.00</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>17.41</td>\n",
              "      <td>17.86</td>\n",
              "      <td>18.41</td>\n",
              "      <td>14.37</td>\n",
              "      <td>19.69</td>\n",
              "      <td>20.28</td>\n",
              "      <td>10.01</td>\n",
              "      <td>10.77</td>\n",
              "      <td>9.44</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7.70</td>\n",
              "      <td>44.84</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>239000</td>\n",
              "      <td>-109.52</td>\n",
              "      <td>40.46</td>\n",
              "      <td>1411.00</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>62.06</td>\n",
              "      <td>64.14</td>\n",
              "      <td>35.28</td>\n",
              "      <td>36.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>34.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>50.65</td>\n",
              "      <td>0.00</td>\n",
              "      <td>9.03</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>3.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>529000</td>\n",
              "      <td>-111.41</td>\n",
              "      <td>41.97</td>\n",
              "      <td>2233.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.14</td>\n",
              "      <td>15.55</td>\n",
              "      <td>15.05</td>\n",
              "      <td>14.62</td>\n",
              "      <td>50.34</td>\n",
              "      <td>31.18</td>\n",
              "      <td>45.92</td>\n",
              "      <td>66.25</td>\n",
              "      <td>14.64</td>\n",
              "      <td>21.56</td>\n",
              "      <td>10.39</td>\n",
              "      <td>12.35</td>\n",
              "      <td>14.40</td>\n",
              "      <td>8.84</td>\n",
              "      <td>11.54</td>\n",
              "      <td>11.94</td>\n",
              "      <td>7.74</td>\n",
              "      <td>11.44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>976</th>\n",
              "      <td>4.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>2200000</td>\n",
              "      <td>-111.88</td>\n",
              "      <td>40.78</td>\n",
              "      <td>5518.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.00</td>\n",
              "      <td>9.51</td>\n",
              "      <td>8.95</td>\n",
              "      <td>46.09</td>\n",
              "      <td>32.78</td>\n",
              "      <td>47.41</td>\n",
              "      <td>47.69</td>\n",
              "      <td>20.04</td>\n",
              "      <td>17.29</td>\n",
              "      <td>0.00</td>\n",
              "      <td>18.36</td>\n",
              "      <td>10.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>9.62</td>\n",
              "      <td>13.35</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>4.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>127000</td>\n",
              "      <td>-113.62</td>\n",
              "      <td>37.19</td>\n",
              "      <td>2781.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>17.01</td>\n",
              "      <td>7.29</td>\n",
              "      <td>23.98</td>\n",
              "      <td>27.92</td>\n",
              "      <td>17.71</td>\n",
              "      <td>10.86</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>457 rows × 114 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     bedrooms  bathrooms    price  ...  city_St George  city_Vernal  city_Washington\n",
              "531      3.00       2.00   325000  ...               0            0                0\n",
              "451      4.00       2.00   299000  ...               0            0                0\n",
              "845      4.00       2.00   549000  ...               0            0                0\n",
              "15       4.00       3.00   465000  ...               0            0                0\n",
              "493      3.00       1.00   425000  ...               0            0                0\n",
              "..        ...        ...      ...  ...             ...          ...              ...\n",
              "586      3.00       2.00   299900  ...               0            0                0\n",
              "5        3.00       2.00   239000  ...               0            1                0\n",
              "245      3.00       2.00   529000  ...               0            0                0\n",
              "976      4.00       6.00  2200000  ...               0            0                0\n",
              "326      4.00       6.00   127000  ...               0            0                0\n",
              "\n",
              "[457 rows x 114 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calinski and Harabasz (CH) criterion"
      ],
      "metadata": {
        "id": "wSLynBXRWunF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ch_criterion(df_dummies)"
      ],
      "metadata": {
        "id": "GGORXrKFVmw8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "218411a3-7f2c-4816-9c60-729ccfed4d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Silhouette Analysis\n"
      ],
      "metadata": {
        "id": "0genNIG4W0jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_analysis(df_dummies)"
      ],
      "metadata": {
        "id": "KOG62I_3V1fW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "b30fb16e-2206-4401-e4a4-5bdeb22cb463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WCSS: Elbow Method\n"
      ],
      "metadata": {
        "id": "v5uYz_ePW4k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elbow_method(df_dummies)"
      ],
      "metadata": {
        "id": "RbYdbM4eV6Pl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0942177d-a37a-4965-e8e2-a15d73c2fd6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "from sklearn.cluster import KMeans\n",
        "kmeans_model = KMeans(6, random_state=12345).fit(df_dummies)\n",
        "\n",
        "# Add assigned clusters to a new DataFrame\n",
        "df_wcluster = df_dummies.copy()\n",
        "df_wcluster['cluster'] = kmeans_model.labels_\n",
        "\n",
        "# dumps into a sav\n",
        "dump_pickle(model, 'saved_model_cluster.sav')\n",
        "\n",
        "df_wcluster.head()"
      ],
      "metadata": {
        "id": "jqB6irZiWBWu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "0aa2bbab-ab10-4109-bfec-72d7b1243981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>price</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>livingArea</th>\n",
              "      <th>sentiment_overall</th>\n",
              "      <th>sentiment_neg</th>\n",
              "      <th>sentiment_neu</th>\n",
              "      <th>sentiment_pos</th>\n",
              "      <th>topic_1</th>\n",
              "      <th>topic_2</th>\n",
              "      <th>topic_3</th>\n",
              "      <th>topic_4</th>\n",
              "      <th>topic_5</th>\n",
              "      <th>fence</th>\n",
              "      <th>grass</th>\n",
              "      <th>housing</th>\n",
              "      <th>house</th>\n",
              "      <th>home</th>\n",
              "      <th>architecture</th>\n",
              "      <th>building</th>\n",
              "      <th>tree</th>\n",
              "      <th>roof</th>\n",
              "      <th>lawn</th>\n",
              "      <th>window</th>\n",
              "      <th>brick</th>\n",
              "      <th>garage</th>\n",
              "      <th>windows</th>\n",
              "      <th>modern</th>\n",
              "      <th>bungalow</th>\n",
              "      <th>door</th>\n",
              "      <th>yearBuilt_1956.0</th>\n",
              "      <th>yearBuilt_1976.0</th>\n",
              "      <th>yearBuilt_1978.0</th>\n",
              "      <th>yearBuilt_1980.0</th>\n",
              "      <th>yearBuilt_1982.0</th>\n",
              "      <th>yearBuilt_1983.0</th>\n",
              "      <th>yearBuilt_1984.0</th>\n",
              "      <th>yearBuilt_1985.0</th>\n",
              "      <th>...</th>\n",
              "      <th>zipcode_84066</th>\n",
              "      <th>zipcode_84074</th>\n",
              "      <th>zipcode_84078</th>\n",
              "      <th>zipcode_84098</th>\n",
              "      <th>zipcode_84501</th>\n",
              "      <th>zipcode_84532</th>\n",
              "      <th>zipcode_84647</th>\n",
              "      <th>zipcode_84720</th>\n",
              "      <th>zipcode_84721</th>\n",
              "      <th>zipcode_84737</th>\n",
              "      <th>zipcode_84745</th>\n",
              "      <th>zipcode_84770</th>\n",
              "      <th>zipcode_84780</th>\n",
              "      <th>zipcode_84790</th>\n",
              "      <th>zipcode_Other</th>\n",
              "      <th>city_Cedar City</th>\n",
              "      <th>city_Eagle Mountain</th>\n",
              "      <th>city_Garden City</th>\n",
              "      <th>city_Heber City</th>\n",
              "      <th>city_Hurricane</th>\n",
              "      <th>city_Kamas</th>\n",
              "      <th>city_La Verkin</th>\n",
              "      <th>city_Lehi</th>\n",
              "      <th>city_Midway</th>\n",
              "      <th>city_Moab</th>\n",
              "      <th>city_Mount Pleasant</th>\n",
              "      <th>city_Ogden</th>\n",
              "      <th>city_Orem</th>\n",
              "      <th>city_Other</th>\n",
              "      <th>city_Park City</th>\n",
              "      <th>city_Price</th>\n",
              "      <th>city_Provo</th>\n",
              "      <th>city_Roosevelt</th>\n",
              "      <th>city_Saint George</th>\n",
              "      <th>city_Salt Lake City</th>\n",
              "      <th>city_South Jordan</th>\n",
              "      <th>city_St George</th>\n",
              "      <th>city_Vernal</th>\n",
              "      <th>city_Washington</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>3.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>325000</td>\n",
              "      <td>-113.63</td>\n",
              "      <td>37.42</td>\n",
              "      <td>1792.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>19.03</td>\n",
              "      <td>16.71</td>\n",
              "      <td>64.55</td>\n",
              "      <td>54.41</td>\n",
              "      <td>43.92</td>\n",
              "      <td>33.75</td>\n",
              "      <td>14.66</td>\n",
              "      <td>27.78</td>\n",
              "      <td>17.02</td>\n",
              "      <td>12.12</td>\n",
              "      <td>29.91</td>\n",
              "      <td>72.21</td>\n",
              "      <td>21.19</td>\n",
              "      <td>16.88</td>\n",
              "      <td>16.16</td>\n",
              "      <td>16.22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>4.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>299000</td>\n",
              "      <td>-111.71</td>\n",
              "      <td>39.11</td>\n",
              "      <td>2100.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13.47</td>\n",
              "      <td>90.12</td>\n",
              "      <td>72.04</td>\n",
              "      <td>59.17</td>\n",
              "      <td>46.33</td>\n",
              "      <td>32.14</td>\n",
              "      <td>11.56</td>\n",
              "      <td>22.94</td>\n",
              "      <td>15.12</td>\n",
              "      <td>16.52</td>\n",
              "      <td>19.82</td>\n",
              "      <td>44.25</td>\n",
              "      <td>21.18</td>\n",
              "      <td>18.98</td>\n",
              "      <td>77.32</td>\n",
              "      <td>24.03</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>4.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>549000</td>\n",
              "      <td>-113.09</td>\n",
              "      <td>37.75</td>\n",
              "      <td>3404.00</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>22.97</td>\n",
              "      <td>19.05</td>\n",
              "      <td>68.74</td>\n",
              "      <td>64.72</td>\n",
              "      <td>55.66</td>\n",
              "      <td>40.11</td>\n",
              "      <td>13.87</td>\n",
              "      <td>23.60</td>\n",
              "      <td>22.66</td>\n",
              "      <td>17.60</td>\n",
              "      <td>40.28</td>\n",
              "      <td>47.28</td>\n",
              "      <td>25.97</td>\n",
              "      <td>21.77</td>\n",
              "      <td>35.24</td>\n",
              "      <td>20.46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>465000</td>\n",
              "      <td>-113.54</td>\n",
              "      <td>37.11</td>\n",
              "      <td>1920.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.00</td>\n",
              "      <td>8.41</td>\n",
              "      <td>23.76</td>\n",
              "      <td>12.02</td>\n",
              "      <td>49.84</td>\n",
              "      <td>40.75</td>\n",
              "      <td>43.39</td>\n",
              "      <td>77.45</td>\n",
              "      <td>22.31</td>\n",
              "      <td>15.39</td>\n",
              "      <td>20.78</td>\n",
              "      <td>12.18</td>\n",
              "      <td>20.90</td>\n",
              "      <td>11.36</td>\n",
              "      <td>15.39</td>\n",
              "      <td>14.05</td>\n",
              "      <td>15.13</td>\n",
              "      <td>13.34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>3.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>425000</td>\n",
              "      <td>-111.87</td>\n",
              "      <td>40.72</td>\n",
              "      <td>1100.00</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>7.26</td>\n",
              "      <td>19.05</td>\n",
              "      <td>26.08</td>\n",
              "      <td>73.85</td>\n",
              "      <td>67.25</td>\n",
              "      <td>55.94</td>\n",
              "      <td>40.47</td>\n",
              "      <td>12.42</td>\n",
              "      <td>26.50</td>\n",
              "      <td>22.71</td>\n",
              "      <td>15.80</td>\n",
              "      <td>34.16</td>\n",
              "      <td>46.43</td>\n",
              "      <td>25.05</td>\n",
              "      <td>24.63</td>\n",
              "      <td>100.00</td>\n",
              "      <td>22.06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 115 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     bedrooms  bathrooms   price  ...  city_Vernal  city_Washington  cluster\n",
              "531      3.00       2.00  325000  ...            0                0        0\n",
              "451      4.00       2.00  299000  ...            0                0        0\n",
              "845      4.00       2.00  549000  ...            0                0        0\n",
              "15       4.00       3.00  465000  ...            0                0        0\n",
              "493      3.00       1.00  425000  ...            0                0        0\n",
              "\n",
              "[5 rows x 115 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out which features played the largest role in determining clusters?\n",
        "cluster_top_features(df_wcluster)"
      ],
      "metadata": {
        "id": "CADCNZaGWIfV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "cf06a059-20f4-422d-e286-8e24785ec8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C0_means</th>\n",
              "      <th>C1_means</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>490637.32</td>\n",
              "      <td>5571111.11</td>\n",
              "      <td>5080473.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>livingArea</th>\n",
              "      <td>2296.93</td>\n",
              "      <td>6229.22</td>\n",
              "      <td>3932.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>garage</th>\n",
              "      <td>35.39</td>\n",
              "      <td>15.35</td>\n",
              "      <td>20.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>housing</th>\n",
              "      <td>34.32</td>\n",
              "      <td>24.87</td>\n",
              "      <td>9.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>home</th>\n",
              "      <td>49.88</td>\n",
              "      <td>42.49</td>\n",
              "      <td>7.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>topic_4</th>\n",
              "      <td>0.13</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zipcode_84036</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yearBuilt_1984.0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city_Kamas</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment_neg</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  C0_means   C1_means       diff\n",
              "price            490637.32 5571111.11 5080473.79\n",
              "livingArea         2296.93    6229.22    3932.30\n",
              "garage               35.39      15.35      20.04\n",
              "housing              34.32      24.87       9.45\n",
              "home                 49.88      42.49       7.40\n",
              "...                    ...        ...        ...\n",
              "topic_4               0.13       0.14       0.01\n",
              "zipcode_84036         0.01       0.00       0.01\n",
              "yearBuilt_1984.0      0.01       0.00       0.01\n",
              "city_Kamas            0.01       0.00       0.01\n",
              "sentiment_neg         0.01       0.01       0.00\n",
              "\n",
              "[114 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Cluster assignment\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter_3d(df_wcluster, x='price', y='livingArea', z='bathrooms', color='cluster', size_max=20, opacity=1.0)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "y5PPMI2CWWPC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "dc6b7603-8e2f-4a28-c2db-953f13c9be95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"213b6f3f-c912-4824-897f-2525854e6792\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"213b6f3f-c912-4824-897f-2525854e6792\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '213b6f3f-c912-4824-897f-2525854e6792',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"price=%{x}<br>livingArea=%{y}<br>bathrooms=%{z}<br>cluster=%{marker.color}\", \"legendgroup\": \"\", \"marker\": {\"color\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 2, 0, 0, 0, 0, 2, 5, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 4, 5, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 2, 4, 0, 2, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 4, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 5, 4, 2, 0, 5, 0, 0, 1, 5, 0, 2, 0, 2, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 2, 0, 5, 0, 0, 0, 0, 0, 0, 0, 2, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 2, 0, 5, 2, 0, 0, 2, 0, 0, 0, 0, 0, 5, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 1, 5, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 2, 0, 0, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 4, 0, 2, 2, 5, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0], \"coloraxis\": \"coloraxis\", \"opacity\": 1.0, \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"\", \"scene\": \"scene\", \"showlegend\": false, \"type\": \"scatter3d\", \"x\": [325000, 299000, 549000, 465000, 425000, 389000, 89900, 385000, 485900, 565000, 819950, 220000, 604900, 799000, 510000, 525000, 624927, 4000000, 485000, 1649000, 599000, 680640, 419000, 729000, 2000000, 3195000, 465000, 225000, 579000, 1325000, 350000, 661500, 290000, 899000, 509900, 335000, 1460000, 6000000, 7000000, 4450000, 399900, 249900, 1200000, 379900, 215000, 242500, 950000, 2735000, 497000, 972000, 849000, 799990, 1100000, 7350000, 650000, 1735000, 469900, 160000, 3295000, 584900, 725000, 489900, 499000, 618000, 249000, 400000, 625000, 1690000, 999999, 655000, 8400000, 269900, 289000, 475000, 955000, 877500, 589000, 1100000, 225000, 635000, 4950000, 239000, 999000, 525000, 279000, 1595000, 364900, 419900, 310000, 1283173, 305000, 2299000, 825000, 518900, 540000, 875000, 674950, 3480000, 6900000, 1895000, 425000, 2699000, 350000, 546445, 5300000, 2650000, 450000, 1400000, 750000, 1500000, 8800000, 1200000, 450000, 394900, 349000, 199000, 180000, 479900, 550000, 180000, 629000, 1850000, 255000, 410000, 632230, 375000, 799900, 1950000, 200000, 385000, 549999, 1499999, 750000, 159000, 1283173, 420000, 595000, 749900, 1425000, 675000, 489900, 749900, 713785, 545000, 1280000, 3450000, 299898, 340000, 350000, 720000, 274000, 390000, 659900, 385000, 695000, 890000, 450000, 4390000, 439900, 500000, 390000, 323900, 729900, 1100000, 310000, 825000, 850000, 5375000, 379200, 464953, 325000, 525000, 245000, 315000, 230000, 964000, 499000, 249900, 499900, 3800000, 824000, 179000, 349000, 525000, 2495000, 888000, 3450000, 299900, 929000, 440000, 550000, 345000, 385000, 389000, 1300000, 1445000, 3349000, 519900, 399900, 320000, 185000, 990000, 965000, 449900, 54900, 1500000, 525000, 395000, 6500000, 539900, 330000, 1459000, 425000, 767000, 3850000, 390000, 585000, 379900, 850000, 445000, 349900, 309000, 3995000, 799900, 92000, 1750000, 729000, 3250000, 1035000, 495000, 149900, 1250000, 549900, 456900, 615000, 140000, 565000, 3395000, 999999, 419900, 6985000, 390000, 520000, 475000, 465000, 499900, 659000, 659000, 425000, 3950000, 755900, 850000, 567900, 589900, 565000, 5950000, 4200000, 259000, 150000, 699900, 349000, 499900, 1500000, 425000, 199900, 370000, 330000, 725000, 569900, 195000, 1350000, 539900, 850000, 189900, 250000, 189000, 325000, 10000000, 195000, 449999, 160000, 1250000, 595000, 774900, 1079000, 2900000, 969000, 675000, 350000, 225000, 754500, 875000, 248000, 350000, 340000, 640000, 599999, 479000, 3495000, 480000, 459900, 430000, 299500, 795810, 330000, 365000, 475000, 420000, 280000, 625000, 1600000, 1200000, 299900, 1600000, 1250000, 1200000, 425000, 210000, 2500000, 719900, 469900, 599750, 670000, 765000, 1490000, 240000, 895000, 587000, 1300000, 240000, 479000, 679000, 3499000, 595000, 440000, 660000, 7850000, 380000, 1200000, 1895000, 3950000, 499000, 414900, 16995000, 399900, 259900, 388000, 499000, 725000, 525000, 455000, 840000, 450000, 724900, 1275000, 925000, 600000, 449999, 3250000, 335000, 540000, 489000, 699999, 497000, 140000, 540000, 1950000, 750000, 80000, 515000, 379000, 265000, 555000, 199900, 415000, 249000, 1599000, 2500000, 385000, 846736, 449900, 289900, 120000, 1795000, 1050000, 300000, 469000, 297000, 279900, 550000, 402000, 1100000, 365000, 565000, 939000, 985000, 2500000, 705000, 385000, 235000, 1185000, 115000, 349900, 190000, 1429900, 2195000, 589000, 319000, 495000, 4250000, 3990760, 599000, 135000, 315000, 545000, 430000, 3295000, 189900, 379000, 830000, 4920000, 650000, 639315, 560000, 649900, 2299000, 720000, 529000, 8000000, 310000, 449000, 648738, 4995000, 330000, 54900, 799900, 604990, 619900, 200000, 230000, 429000, 3950000, 500000, 569900, 1550000, 680000, 569000, 6150000, 399999, 849900, 670000, 590000, 299900, 239000, 529000, 2200000, 127000], \"y\": [1792.0, 2100.0, 3404.0, 1920.0, 1100.0, 1293.0, 630.0, 2026.0, 2105.0, 2638.0, 2764.0, 1003.0, 2538.0, 3913.0, 1900.0, 1391.0, 3209.0, 4866.0, 3004.0, 7560.0, 4278.0, 2476.0, 1888.0, 3850.0, 9315.0, 4611.0, 1620.0, 1856.0, 3681.0, 4400.0, 1272.0, 2636.0, 2434.0, 5570.0, 1905.0, 1800.0, 7012.0, 6050.0, 7500.0, 6229.0, 2352.0, 1848.0, 3048.0, 2436.0, 1904.0, 1500.0, 4638.0, 5459.0, 768.0, 1803.0, 3916.0, 3674.0, 5152.0, 4920.0, 2978.0, 2638.0, 1865.0, 1042.0, 4862.0, 2850.0, 2095.0, 1891.0, 2345.0, 3200.0, 1014.0, 2361.0, 2412.0, 5700.0, 2200.0, 1907.0, 8446.0, 1886.0, 1196.0, 1880.0, 4811.0, 2957.0, 2582.0, 4823.0, 2250.0, 4006.0, 4391.0, 870.0, 2350.0, 3000.0, 1485.0, 1347.0, 1285.0, 3537.0, 2368.0, 2050.0, 1420.0, 5014.0, 720.0, 2747.0, 2742.0, 2379.0, 3620.0, 6508.0, 0.0, 6626.0, 2105.0, 6372.0, 1440.0, 3038.0, 5300.0, 4239.0, 2648.0, 3000.0, 1868.0, 7010.0, 6915.0, 4198.0, 2124.0, 2794.0, 1026.0, 1572.0, 1988.0, 2816.0, 2174.0, 2356.0, 3158.0, 4126.0, 832.0, 1400.0, 2021.0, 3158.0, 2984.0, 3712.0, 1080.0, 3026.0, 1176.0, 2004.0, 4180.0, 572.0, 2050.0, 4158.0, 980.0, 3603.0, 4300.0, 2774.0, 3300.0, 1676.0, 2947.0, 2976.0, 1703.0, 7164.0, 865.0, 1560.0, 1018.0, 3485.0, 2348.0, 1398.0, 3536.0, 2175.0, 2096.0, 4000.0, 2310.0, 17506.0, 1573.0, 1616.0, 2100.0, 2700.0, 1277.0, 1862.0, 1152.0, 3806.0, 4548.0, 4990.0, 1308.0, 1908.0, 2970.0, 916.0, 1131.0, 1013.0, 936.0, 3866.0, 928.0, 1328.0, 2976.0, 8836.0, 2655.0, 1507.0, 2224.0, 2537.0, 2444.0, 2824.0, 7164.0, 1363.0, 4459.0, 2136.0, 2206.0, 1327.0, 2035.0, 3651.0, 1752.0, 1268.0, 4768.0, 3650.0, 1414.0, 1560.0, 916.0, 3478.0, 4410.0, 2116.0, 950.0, 5720.0, 1840.0, 2117.0, 5977.0, 3244.0, 924.0, 4981.0, 1808.0, 2880.0, 5100.0, 1650.0, 2875.0, 1488.0, 1729.0, 2609.0, 1315.0, 1962.0, 5356.0, 3998.0, 747.0, 1500.0, 2840.0, 2619.0, 3943.0, 2010.0, 1440.0, 5441.0, 3216.0, 930.0, 3024.0, 2569.0, 3256.0, 2482.0, 4130.0, 2430.0, 7267.0, 1720.0, 2617.0, 1507.0, 1646.0, 1328.0, 3506.0, 3702.0, 1537.0, 6016.0, 2770.0, 2928.0, 2227.0, 1713.0, 3931.0, 7508.0, 7954.0, 1720.0, 1160.0, 5751.0, 1319.0, 1602.0, 3967.0, 2250.0, 1616.0, 2352.0, 904.0, 3070.0, 3012.0, 1558.0, 4273.0, 2891.0, 4800.0, 672.0, 1410.0, 2664.0, 3010.0, 9156.0, 1323.0, 1427.0, 1064.0, 3996.0, 3216.0, 3914.0, 3823.0, 3545.0, 2860.0, 2312.0, 2290.0, 1285.0, 2896.0, 2498.0, 1560.0, 3348.0, 1240.0, 2800.0, 3029.0, 1512.0, 22548.0, 1631.0, 2832.0, 1488.0, 1398.0, 3394.0, 1988.0, 1080.0, 1783.0, 4158.0, 1464.0, 2059.0, 8021.0, 5144.0, 2672.0, 2450.0, 3376.0, 2971.0, 1475.0, 2005.0, 3708.0, 4156.0, 2529.0, 2005.0, 4360.0, 2085.0, 6026.0, 1100.0, 3696.0, 3199.0, 4545.0, 1088.0, 2534.0, 1879.0, 4613.0, 3258.0, 1891.0, 2725.0, 5740.0, 1399.0, 2577.0, 4894.0, 9340.0, 3258.0, 1671.0, 13040.0, 1468.0, 1800.0, 1260.0, 3327.0, 2411.0, 2612.0, 1623.0, 4000.0, 2560.0, 2589.0, 4049.0, 6120.0, 2315.0, 1557.0, 6296.0, 2000.0, 2070.0, 2450.0, 3428.0, 2122.0, 1113.0, 3775.0, 4569.0, 3185.0, 1071.0, 2901.0, 2368.0, 1612.0, 2576.0, 1350.0, 1350.0, 1776.0, 4608.0, 2024.0, 1479.0, 3221.0, 2026.0, 1071.0, 980.0, 3879.0, 3291.0, 1561.0, 1762.0, 1968.0, 1140.0, 2001.0, 1658.0, 4664.0, 3796.0, 2357.0, 2404.0, 4450.0, 4703.0, 2832.0, 1215.0, 1965.0, 2505.0, 1456.0, 960.0, 1251.0, 4735.0, 3410.0, 2788.0, 1296.0, 2490.0, 2130.0, 3400.0, 2680.0, 1920.0, 1511.0, 2976.0, 3540.0, 5212.0, 1512.0, 1639.0, 3109.0, 7581.0, 1149.0, 3833.0, 2601.0, 1840.0, 2510.0, 4135.0, 1764.0, 9150.0, 1040.0, 2004.0, 2450.0, 7496.0, 1855.0, 1280.0, 4500.0, 3209.0, 3064.0, 2457.0, 2184.0, 1542.0, 2181.0, 1932.0, 2574.0, 5852.0, 1747.0, 1564.0, 6770.0, 2013.0, 3340.0, 4127.0, 1884.0, 1850.0, 1411.0, 2233.0, 5518.0, 2781.0], \"z\": [2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 1.0, 3.0, 5.0, 4.0, 6.0, 8.0, 3.0, 2.0, 3.0, 7.0, 6.0, 2.0, 2.0, 4.0, 5.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 5.0, 6.0, 7.0, 5.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 5.0, 5.0, 1.0, 3.0, 3.0, 4.0, 7.0, 8.0, 3.0, 4.0, 2.0, 2.0, 6.0, 3.0, 4.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 6.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 5.0, 2.0, 4.0, 6.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 2.0, 3.0, 3.0, 5.0, 1.0, 3.0, 3.0, 3.0, 3.0, 7.0, 8.0, 6.0, 3.0, 5.0, 3.0, 3.0, 4.0, 5.0, 4.0, 3.0, 3.0, 6.0, 6.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 4.0, 1.0, 3.0, 4.0, 3.0, 3.0, 2.0, 5.0, 2.0, 3.0, 7.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 10.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 1.0, 4.0, 4.0, 5.0, 2.0, 3.0, 4.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 7.0, 4.0, 1.0, 1.0, 4.0, 2.0, 4.0, 7.0, 2.0, 4.0, 3.0, 3.0, 3.0, 1.0, 5.0, 4.0, 2.0, 7.0, 3.0, 2.0, 3.0, 1.0, 3.0, 4.0, 2.0, 1.0, 6.0, 2.0, 3.0, 6.0, 3.0, 2.0, 6.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 8.0, 4.0, 1.0, 3.0, 4.0, 4.0, 4.0, 4.0, 2.0, 3.0, 2.0, 1.0, 3.0, 4.0, 3.0, 4.0, 5.0, 3.0, 7.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0, 2.0, 6.0, 4.0, 4.0, 3.0, 2.0, 4.0, 7.0, 7.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0, 2.0, 5.0, 3.0, 4.0, 1.0, 2.0, 2.0, 2.0, 7.0, 2.0, 2.0, 1.0, 5.0, 3.0, 4.0, 5.0, 6.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 2.0, 24.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 4.0, 2.0, 2.0, 6.0, 5.0, 2.0, 2.0, 4.0, 4.0, 2.0, 2.0, 4.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 4.0, 5.0, 2.0, 3.0, 3.0, 5.0, 3.0, 2.0, 3.0, 5.0, 2.0, 4.0, 6.0, 7.0, 2.0, 3.0, 13.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 5.0, 3.0, 2.0, 3.0, 6.0, 2.0, 2.0, 5.0, 2.0, 3.0, 4.0, 4.0, 3.0, 1.0, 3.0, 5.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 5.0, 3.0, 4.0, 3.0, 4.0, 5.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 3.0, 3.0, 5.0, 2.0, 1.0, 3.0, 2.0, 4.0, 6.0, 2.0, 3.0, 5.0, 6.0, 1.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 8.0, 2.0, 3.0, 3.0, 7.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 7.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 6.0, 6.0]}],\n",
              "                        {\"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"cluster\"}}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"scene\": {\"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"xaxis\": {\"title\": {\"text\": \"price\"}}, \"yaxis\": {\"title\": {\"text\": \"livingArea\"}}, \"zaxis\": {\"title\": {\"text\": \"bathrooms\"}}}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('213b6f3f-c912-4824-897f-2525854e6792');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gower\n",
        "distance_matrix = gower.gower_matrix(df)\n",
        "pd.DataFrame(distance_matrix).head()"
      ],
      "metadata": {
        "id": "flalt8VKWbs3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "b662f208-9780-4f75-8f61-110a4f121e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>417</th>\n",
              "      <th>418</th>\n",
              "      <th>419</th>\n",
              "      <th>420</th>\n",
              "      <th>421</th>\n",
              "      <th>422</th>\n",
              "      <th>423</th>\n",
              "      <th>424</th>\n",
              "      <th>425</th>\n",
              "      <th>426</th>\n",
              "      <th>427</th>\n",
              "      <th>428</th>\n",
              "      <th>429</th>\n",
              "      <th>430</th>\n",
              "      <th>431</th>\n",
              "      <th>432</th>\n",
              "      <th>433</th>\n",
              "      <th>434</th>\n",
              "      <th>435</th>\n",
              "      <th>436</th>\n",
              "      <th>437</th>\n",
              "      <th>438</th>\n",
              "      <th>439</th>\n",
              "      <th>440</th>\n",
              "      <th>441</th>\n",
              "      <th>442</th>\n",
              "      <th>443</th>\n",
              "      <th>444</th>\n",
              "      <th>445</th>\n",
              "      <th>446</th>\n",
              "      <th>447</th>\n",
              "      <th>448</th>\n",
              "      <th>449</th>\n",
              "      <th>450</th>\n",
              "      <th>451</th>\n",
              "      <th>452</th>\n",
              "      <th>453</th>\n",
              "      <th>454</th>\n",
              "      <th>455</th>\n",
              "      <th>456</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.29</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.31</td>\n",
              "      <td>...</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.29</td>\n",
              "      <td>...</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.13</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.26</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.19</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 457 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5    6    ...  450  451  452  453  454  455  456\n",
              "0 0.00 0.12 0.12 0.13 0.19 0.17 0.22  ... 0.20 0.23 0.20 0.29 0.19 0.21 0.25\n",
              "1 0.12 0.00 0.13 0.18 0.18 0.20 0.21  ... 0.16 0.24 0.22 0.30 0.21 0.22 0.28\n",
              "2 0.12 0.13 0.00 0.16 0.16 0.17 0.25  ... 0.16 0.26 0.23 0.29 0.21 0.23 0.27\n",
              "3 0.13 0.18 0.16 0.00 0.24 0.13 0.20  ... 0.25 0.22 0.20 0.28 0.16 0.19 0.19\n",
              "4 0.19 0.18 0.16 0.24 0.00 0.23 0.21  ... 0.12 0.26 0.28 0.25 0.23 0.23 0.32\n",
              "\n",
              "[5 rows x 457 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "df_agg = df.copy()\n",
        "agg = AgglomerativeClustering(affinity=\"precomputed\", linkage=\"average\").fit(distance_matrix)\n",
        "df_agg['agg_cluster'] = agg.labels_\n",
        "\n",
        "\n",
        "fig = px.scatter_3d(df_agg, x='price', y='livingArea', z='bathrooms', color='agg_cluster', size_max=50, opacity=1.0)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "mrK7SP1CWeZN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "aedef0e0-ef10-4af9-86a7-bbf59c6221b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"46894323-0923-4824-a708-b9a44f022285\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"46894323-0923-4824-a708-b9a44f022285\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '46894323-0923-4824-a708-b9a44f022285',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"price=%{x}<br>livingArea=%{y}<br>bathrooms=%{z}<br>agg_cluster=%{marker.color}\", \"legendgroup\": \"\", \"marker\": {\"color\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0], \"coloraxis\": \"coloraxis\", \"opacity\": 1.0, \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"\", \"scene\": \"scene\", \"showlegend\": false, \"type\": \"scatter3d\", \"x\": [325000, 299000, 549000, 465000, 425000, 389000, 89900, 385000, 485900, 565000, 819950, 220000, 604900, 799000, 510000, 525000, 624927, 4000000, 485000, 1649000, 599000, 680640, 419000, 729000, 2000000, 3195000, 465000, 225000, 579000, 1325000, 350000, 661500, 290000, 899000, 509900, 335000, 1460000, 6000000, 7000000, 4450000, 399900, 249900, 1200000, 379900, 215000, 242500, 950000, 2735000, 497000, 972000, 849000, 799990, 1100000, 7350000, 650000, 1735000, 469900, 160000, 3295000, 584900, 725000, 489900, 499000, 618000, 249000, 400000, 625000, 1690000, 999999, 655000, 8400000, 269900, 289000, 475000, 955000, 877500, 589000, 1100000, 225000, 635000, 4950000, 239000, 999000, 525000, 279000, 1595000, 364900, 419900, 310000, 1283173, 305000, 2299000, 825000, 518900, 540000, 875000, 674950, 3480000, 6900000, 1895000, 425000, 2699000, 350000, 546445, 5300000, 2650000, 450000, 1400000, 750000, 1500000, 8800000, 1200000, 450000, 394900, 349000, 199000, 180000, 479900, 550000, 180000, 629000, 1850000, 255000, 410000, 632230, 375000, 799900, 1950000, 200000, 385000, 549999, 1499999, 750000, 159000, 1283173, 420000, 595000, 749900, 1425000, 675000, 489900, 749900, 713785, 545000, 1280000, 3450000, 299898, 340000, 350000, 720000, 274000, 390000, 659900, 385000, 695000, 890000, 450000, 4390000, 439900, 500000, 390000, 323900, 729900, 1100000, 310000, 825000, 850000, 5375000, 379200, 464953, 325000, 525000, 245000, 315000, 230000, 964000, 499000, 249900, 499900, 3800000, 824000, 179000, 349000, 525000, 2495000, 888000, 3450000, 299900, 929000, 440000, 550000, 345000, 385000, 389000, 1300000, 1445000, 3349000, 519900, 399900, 320000, 185000, 990000, 965000, 449900, 54900, 1500000, 525000, 395000, 6500000, 539900, 330000, 1459000, 425000, 767000, 3850000, 390000, 585000, 379900, 850000, 445000, 349900, 309000, 3995000, 799900, 92000, 1750000, 729000, 3250000, 1035000, 495000, 149900, 1250000, 549900, 456900, 615000, 140000, 565000, 3395000, 999999, 419900, 6985000, 390000, 520000, 475000, 465000, 499900, 659000, 659000, 425000, 3950000, 755900, 850000, 567900, 589900, 565000, 5950000, 4200000, 259000, 150000, 699900, 349000, 499900, 1500000, 425000, 199900, 370000, 330000, 725000, 569900, 195000, 1350000, 539900, 850000, 189900, 250000, 189000, 325000, 10000000, 195000, 449999, 160000, 1250000, 595000, 774900, 1079000, 2900000, 969000, 675000, 350000, 225000, 754500, 875000, 248000, 350000, 340000, 640000, 599999, 479000, 3495000, 480000, 459900, 430000, 299500, 795810, 330000, 365000, 475000, 420000, 280000, 625000, 1600000, 1200000, 299900, 1600000, 1250000, 1200000, 425000, 210000, 2500000, 719900, 469900, 599750, 670000, 765000, 1490000, 240000, 895000, 587000, 1300000, 240000, 479000, 679000, 3499000, 595000, 440000, 660000, 7850000, 380000, 1200000, 1895000, 3950000, 499000, 414900, 16995000, 399900, 259900, 388000, 499000, 725000, 525000, 455000, 840000, 450000, 724900, 1275000, 925000, 600000, 449999, 3250000, 335000, 540000, 489000, 699999, 497000, 140000, 540000, 1950000, 750000, 80000, 515000, 379000, 265000, 555000, 199900, 415000, 249000, 1599000, 2500000, 385000, 846736, 449900, 289900, 120000, 1795000, 1050000, 300000, 469000, 297000, 279900, 550000, 402000, 1100000, 365000, 565000, 939000, 985000, 2500000, 705000, 385000, 235000, 1185000, 115000, 349900, 190000, 1429900, 2195000, 589000, 319000, 495000, 4250000, 3990760, 599000, 135000, 315000, 545000, 430000, 3295000, 189900, 379000, 830000, 4920000, 650000, 639315, 560000, 649900, 2299000, 720000, 529000, 8000000, 310000, 449000, 648738, 4995000, 330000, 54900, 799900, 604990, 619900, 200000, 230000, 429000, 3950000, 500000, 569900, 1550000, 680000, 569000, 6150000, 399999, 849900, 670000, 590000, 299900, 239000, 529000, 2200000, 127000], \"y\": [1792.0, 2100.0, 3404.0, 1920.0, 1100.0, 1293.0, 630.0, 2026.0, 2105.0, 2638.0, 2764.0, 1003.0, 2538.0, 3913.0, 1900.0, 1391.0, 3209.0, 4866.0, 3004.0, 7560.0, 4278.0, 2476.0, 1888.0, 3850.0, 9315.0, 4611.0, 1620.0, 1856.0, 3681.0, 4400.0, 1272.0, 2636.0, 2434.0, 5570.0, 1905.0, 1800.0, 7012.0, 6050.0, 7500.0, 6229.0, 2352.0, 1848.0, 3048.0, 2436.0, 1904.0, 1500.0, 4638.0, 5459.0, 768.0, 1803.0, 3916.0, 3674.0, 5152.0, 4920.0, 2978.0, 2638.0, 1865.0, 1042.0, 4862.0, 2850.0, 2095.0, 1891.0, 2345.0, 3200.0, 1014.0, 2361.0, 2412.0, 5700.0, 2200.0, 1907.0, 8446.0, 1886.0, 1196.0, 1880.0, 4811.0, 2957.0, 2582.0, 4823.0, 2250.0, 4006.0, 4391.0, 870.0, 2350.0, 3000.0, 1485.0, 1347.0, 1285.0, 3537.0, 2368.0, 2050.0, 1420.0, 5014.0, 720.0, 2747.0, 2742.0, 2379.0, 3620.0, 6508.0, 0.0, 6626.0, 2105.0, 6372.0, 1440.0, 3038.0, 5300.0, 4239.0, 2648.0, 3000.0, 1868.0, 7010.0, 6915.0, 4198.0, 2124.0, 2794.0, 1026.0, 1572.0, 1988.0, 2816.0, 2174.0, 2356.0, 3158.0, 4126.0, 832.0, 1400.0, 2021.0, 3158.0, 2984.0, 3712.0, 1080.0, 3026.0, 1176.0, 2004.0, 4180.0, 572.0, 2050.0, 4158.0, 980.0, 3603.0, 4300.0, 2774.0, 3300.0, 1676.0, 2947.0, 2976.0, 1703.0, 7164.0, 865.0, 1560.0, 1018.0, 3485.0, 2348.0, 1398.0, 3536.0, 2175.0, 2096.0, 4000.0, 2310.0, 17506.0, 1573.0, 1616.0, 2100.0, 2700.0, 1277.0, 1862.0, 1152.0, 3806.0, 4548.0, 4990.0, 1308.0, 1908.0, 2970.0, 916.0, 1131.0, 1013.0, 936.0, 3866.0, 928.0, 1328.0, 2976.0, 8836.0, 2655.0, 1507.0, 2224.0, 2537.0, 2444.0, 2824.0, 7164.0, 1363.0, 4459.0, 2136.0, 2206.0, 1327.0, 2035.0, 3651.0, 1752.0, 1268.0, 4768.0, 3650.0, 1414.0, 1560.0, 916.0, 3478.0, 4410.0, 2116.0, 950.0, 5720.0, 1840.0, 2117.0, 5977.0, 3244.0, 924.0, 4981.0, 1808.0, 2880.0, 5100.0, 1650.0, 2875.0, 1488.0, 1729.0, 2609.0, 1315.0, 1962.0, 5356.0, 3998.0, 747.0, 1500.0, 2840.0, 2619.0, 3943.0, 2010.0, 1440.0, 5441.0, 3216.0, 930.0, 3024.0, 2569.0, 3256.0, 2482.0, 4130.0, 2430.0, 7267.0, 1720.0, 2617.0, 1507.0, 1646.0, 1328.0, 3506.0, 3702.0, 1537.0, 6016.0, 2770.0, 2928.0, 2227.0, 1713.0, 3931.0, 7508.0, 7954.0, 1720.0, 1160.0, 5751.0, 1319.0, 1602.0, 3967.0, 2250.0, 1616.0, 2352.0, 904.0, 3070.0, 3012.0, 1558.0, 4273.0, 2891.0, 4800.0, 672.0, 1410.0, 2664.0, 3010.0, 9156.0, 1323.0, 1427.0, 1064.0, 3996.0, 3216.0, 3914.0, 3823.0, 3545.0, 2860.0, 2312.0, 2290.0, 1285.0, 2896.0, 2498.0, 1560.0, 3348.0, 1240.0, 2800.0, 3029.0, 1512.0, 22548.0, 1631.0, 2832.0, 1488.0, 1398.0, 3394.0, 1988.0, 1080.0, 1783.0, 4158.0, 1464.0, 2059.0, 8021.0, 5144.0, 2672.0, 2450.0, 3376.0, 2971.0, 1475.0, 2005.0, 3708.0, 4156.0, 2529.0, 2005.0, 4360.0, 2085.0, 6026.0, 1100.0, 3696.0, 3199.0, 4545.0, 1088.0, 2534.0, 1879.0, 4613.0, 3258.0, 1891.0, 2725.0, 5740.0, 1399.0, 2577.0, 4894.0, 9340.0, 3258.0, 1671.0, 13040.0, 1468.0, 1800.0, 1260.0, 3327.0, 2411.0, 2612.0, 1623.0, 4000.0, 2560.0, 2589.0, 4049.0, 6120.0, 2315.0, 1557.0, 6296.0, 2000.0, 2070.0, 2450.0, 3428.0, 2122.0, 1113.0, 3775.0, 4569.0, 3185.0, 1071.0, 2901.0, 2368.0, 1612.0, 2576.0, 1350.0, 1350.0, 1776.0, 4608.0, 2024.0, 1479.0, 3221.0, 2026.0, 1071.0, 980.0, 3879.0, 3291.0, 1561.0, 1762.0, 1968.0, 1140.0, 2001.0, 1658.0, 4664.0, 3796.0, 2357.0, 2404.0, 4450.0, 4703.0, 2832.0, 1215.0, 1965.0, 2505.0, 1456.0, 960.0, 1251.0, 4735.0, 3410.0, 2788.0, 1296.0, 2490.0, 2130.0, 3400.0, 2680.0, 1920.0, 1511.0, 2976.0, 3540.0, 5212.0, 1512.0, 1639.0, 3109.0, 7581.0, 1149.0, 3833.0, 2601.0, 1840.0, 2510.0, 4135.0, 1764.0, 9150.0, 1040.0, 2004.0, 2450.0, 7496.0, 1855.0, 1280.0, 4500.0, 3209.0, 3064.0, 2457.0, 2184.0, 1542.0, 2181.0, 1932.0, 2574.0, 5852.0, 1747.0, 1564.0, 6770.0, 2013.0, 3340.0, 4127.0, 1884.0, 1850.0, 1411.0, 2233.0, 5518.0, 2781.0], \"z\": [2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 1.0, 3.0, 5.0, 4.0, 6.0, 8.0, 3.0, 2.0, 3.0, 7.0, 6.0, 2.0, 2.0, 4.0, 5.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 5.0, 6.0, 7.0, 5.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 5.0, 5.0, 1.0, 3.0, 3.0, 4.0, 7.0, 8.0, 3.0, 4.0, 2.0, 2.0, 6.0, 3.0, 4.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 6.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 5.0, 2.0, 4.0, 6.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 2.0, 3.0, 3.0, 5.0, 1.0, 3.0, 3.0, 3.0, 3.0, 7.0, 8.0, 6.0, 3.0, 5.0, 3.0, 3.0, 4.0, 5.0, 4.0, 3.0, 3.0, 6.0, 6.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 4.0, 1.0, 3.0, 4.0, 3.0, 3.0, 2.0, 5.0, 2.0, 3.0, 7.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 10.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 1.0, 4.0, 4.0, 5.0, 2.0, 3.0, 4.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 7.0, 4.0, 1.0, 1.0, 4.0, 2.0, 4.0, 7.0, 2.0, 4.0, 3.0, 3.0, 3.0, 1.0, 5.0, 4.0, 2.0, 7.0, 3.0, 2.0, 3.0, 1.0, 3.0, 4.0, 2.0, 1.0, 6.0, 2.0, 3.0, 6.0, 3.0, 2.0, 6.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 8.0, 4.0, 1.0, 3.0, 4.0, 4.0, 4.0, 4.0, 2.0, 3.0, 2.0, 1.0, 3.0, 4.0, 3.0, 4.0, 5.0, 3.0, 7.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0, 2.0, 6.0, 4.0, 4.0, 3.0, 2.0, 4.0, 7.0, 7.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0, 2.0, 5.0, 3.0, 4.0, 1.0, 2.0, 2.0, 2.0, 7.0, 2.0, 2.0, 1.0, 5.0, 3.0, 4.0, 5.0, 6.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 2.0, 24.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 4.0, 2.0, 2.0, 6.0, 5.0, 2.0, 2.0, 4.0, 4.0, 2.0, 2.0, 4.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 4.0, 5.0, 2.0, 3.0, 3.0, 5.0, 3.0, 2.0, 3.0, 5.0, 2.0, 4.0, 6.0, 7.0, 2.0, 3.0, 13.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 5.0, 3.0, 2.0, 3.0, 6.0, 2.0, 2.0, 5.0, 2.0, 3.0, 4.0, 4.0, 3.0, 1.0, 3.0, 5.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 5.0, 3.0, 4.0, 3.0, 4.0, 5.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 3.0, 3.0, 5.0, 2.0, 1.0, 3.0, 2.0, 4.0, 6.0, 2.0, 3.0, 5.0, 6.0, 1.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 8.0, 2.0, 3.0, 3.0, 7.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 7.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 6.0, 6.0]}],\n",
              "                        {\"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"agg_cluster\"}}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"b\": 0, \"l\": 0, \"r\": 0, \"t\": 0}, \"scene\": {\"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"xaxis\": {\"title\": {\"text\": \"price\"}}, \"yaxis\": {\"title\": {\"text\": \"livingArea\"}}, \"zaxis\": {\"title\": {\"text\": \"bathrooms\"}}}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('46894323-0923-4824-a708-b9a44f022285');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}